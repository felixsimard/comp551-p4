{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "results-reproduction.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "O04oFcDQekud",
        "eZXxaCaPSt54",
        "_lZAmfLE37SQ"
      ],
      "mount_file_id": "1CfQhsbf3C2BokXiO9I4HPzH5mYzOVH8Z",
      "authorship_tag": "ABX9TyNPghXuHemYoFh5EufLl60U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/felixsimard/comp551-p4/blob/main/results_reproduction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf apex\n",
        "!rm -rf fairseq"
      ],
      "metadata": {
        "id": "5fwy5a3UVWLw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install required dependencies"
      ],
      "metadata": {
        "id": "O04oFcDQekud"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorboardX"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tStByDn0T3U",
        "outputId": "c8f7dfeb-3adf-4b8a-a9ef-b29ccfba5347"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.4.1-py2.py3-none-any.whl (124 kB)\n",
            "\u001b[?25l\r\u001b[K     |██▋                             | 10 kB 22.6 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 20 kB 27.7 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 30 kB 18.2 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 40 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 51 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 61 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 71 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 81 kB 10.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 92 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 102 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 112 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 122 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 124 kB 8.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (3.17.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (1.19.5)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorboardX) (1.15.0)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/pytorch/fairseq\n",
        "%cd fairseq\n",
        "!pip install --editable ./\n",
        "%cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SRqzvcR3Tzwm",
        "outputId": "ad232cd1-7539-44c2-c723-c426f36cc3af"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'fairseq'...\n",
            "remote: Enumerating objects: 30144, done.\u001b[K\n",
            "remote: Counting objects: 100% (1301/1301), done.\u001b[K\n",
            "remote: Compressing objects: 100% (827/827), done.\u001b[K\n",
            "remote: Total 30144 (delta 647), reused 979 (delta 453), pack-reused 28843\u001b[K\n",
            "Receiving objects: 100% (30144/30144), 14.23 MiB | 24.82 MiB/s, done.\n",
            "Resolving deltas: 100% (22320/22320), done.\n",
            "/content/fairseq\n",
            "Obtaining file:///content/fairseq\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+8548f1d) (1.19.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+8548f1d) (1.10.0+cu111)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+8548f1d) (0.29.24)\n",
            "Collecting bitarray\n",
            "  Downloading bitarray-2.3.4.tar.gz (88 kB)\n",
            "\u001b[K     |████████████████████████████████| 88 kB 5.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+8548f1d) (4.62.3)\n",
            "Collecting hydra-core<1.1,>=1.0.7\n",
            "  Downloading hydra_core-1.0.7-py3-none-any.whl (123 kB)\n",
            "\u001b[K     |████████████████████████████████| 123 kB 59.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+8548f1d) (2019.12.20)\n",
            "Requirement already satisfied: torchaudio>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+8548f1d) (0.10.0+cu111)\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.7/dist-packages (from fairseq==1.0.0a0+8548f1d) (1.15.0)\n",
            "Collecting omegaconf<2.1\n",
            "  Downloading omegaconf-2.0.6-py3-none-any.whl (36 kB)\n",
            "Collecting sacrebleu>=1.4.12\n",
            "  Downloading sacrebleu-2.0.0-py3-none-any.whl (90 kB)\n",
            "\u001b[K     |████████████████████████████████| 90 kB 10.6 MB/s \n",
            "\u001b[?25hCollecting antlr4-python3-runtime==4.8\n",
            "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 54.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from hydra-core<1.1,>=1.0.7->fairseq==1.0.0a0+8548f1d) (5.4.0)\n",
            "Collecting PyYAML>=5.1.*\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 59.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from omegaconf<2.1->fairseq==1.0.0a0+8548f1d) (3.10.0.2)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.3.2-py2.py3-none-any.whl (15 kB)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu>=1.4.12->fairseq==1.0.0a0+8548f1d) (0.8.9)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi->fairseq==1.0.0a0+8548f1d) (2.21)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources->hydra-core<1.1,>=1.0.7->fairseq==1.0.0a0+8548f1d) (3.6.0)\n",
            "Building wheels for collected packages: antlr4-python3-runtime, bitarray\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141230 sha256=106755145e3232eff9fcb9c64ecc701f5210a6e3b395f5ae2764cfca31d54dd9\n",
            "  Stored in directory: /root/.cache/pip/wheels/ca/33/b7/336836125fc9bb4ceaa4376d8abca10ca8bc84ddc824baea6c\n",
            "  Building wheel for bitarray (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bitarray: filename=bitarray-2.3.4-cp37-cp37m-linux_x86_64.whl size=171990 sha256=cb7bd4b5e64422831961982bab286d03949d98234d612c059fa229112e302fdf\n",
            "  Stored in directory: /root/.cache/pip/wheels/84/cc/5b/0e861bdb5294d22d2d4f595df936f964a95258387e11494d41\n",
            "Successfully built antlr4-python3-runtime bitarray\n",
            "Installing collected packages: PyYAML, portalocker, omegaconf, colorama, antlr4-python3-runtime, sacrebleu, hydra-core, bitarray, fairseq\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Running setup.py develop for fairseq\n",
            "Successfully installed PyYAML-6.0 antlr4-python3-runtime-4.8 bitarray-2.3.4 colorama-0.4.4 fairseq-1.0.0a0+8548f1d hydra-core-1.0.7 omegaconf-2.0.6 portalocker-2.3.2 sacrebleu-2.0.0\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/NVIDIA/apex\n",
        "%cd apex\n",
        "!pip install -v --disable-pip-version-check --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./\n",
        "%cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7wf847nUNn4",
        "outputId": "c96d7a4c-aca5-4b44-c7dc-3cad4d41a377"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'apex'...\n",
            "remote: Enumerating objects: 8717, done.\u001b[K\n",
            "remote: Counting objects: 100% (1102/1102), done.\u001b[K\n",
            "remote: Compressing objects: 100% (250/250), done.\u001b[K\n",
            "remote: Total 8717 (delta 980), reused 857 (delta 852), pack-reused 7615\u001b[K\n",
            "Receiving objects: 100% (8717/8717), 14.37 MiB | 26.61 MiB/s, done.\n",
            "Resolving deltas: 100% (5961/5961), done.\n",
            "/content/apex\n",
            "/usr/local/lib/python3.7/dist-packages/pip/_internal/commands/install.py:232: UserWarning: Disabling all use of wheels due to the use of --build-option / --global-option / --install-option.\n",
            "  cmdoptions.check_install_build_global(options)\n",
            "Using pip 21.1.3 from /usr/local/lib/python3.7/dist-packages/pip (python 3.7)\n",
            "Value for scheme.platlib does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "distutils: /usr/local/lib/python3.7/dist-packages\n",
            "sysconfig: /usr/lib/python3.7/site-packages\n",
            "Value for scheme.purelib does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "distutils: /usr/local/lib/python3.7/dist-packages\n",
            "sysconfig: /usr/lib/python3.7/site-packages\n",
            "Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "distutils: /usr/local/include/python3.7/UNKNOWN\n",
            "sysconfig: /usr/include/python3.7m/UNKNOWN\n",
            "Value for scheme.scripts does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "distutils: /usr/local/bin\n",
            "sysconfig: /usr/bin\n",
            "Value for scheme.data does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "distutils: /usr/local\n",
            "sysconfig: /usr\n",
            "Additional context:\n",
            "user = False\n",
            "home = None\n",
            "root = None\n",
            "prefix = None\n",
            "Non-user install because site-packages writeable\n",
            "Created temporary directory: /tmp/pip-ephem-wheel-cache-xouiffk9\n",
            "Created temporary directory: /tmp/pip-req-tracker-bfkty70f\n",
            "Initialized build tracking at /tmp/pip-req-tracker-bfkty70f\n",
            "Created build tracker: /tmp/pip-req-tracker-bfkty70f\n",
            "Entered build tracker: /tmp/pip-req-tracker-bfkty70f\n",
            "Created temporary directory: /tmp/pip-install-rdeduo5w\n",
            "Processing /content/apex\n",
            "  Created temporary directory: /tmp/pip-req-build-6kwr9akf\n",
            "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
            "  Added file:///content/apex to build tracker '/tmp/pip-req-tracker-bfkty70f'\n",
            "    Running setup.py (path:/tmp/pip-req-build-6kwr9akf/setup.py) egg_info for package from file:///content/apex\n",
            "    Created temporary directory: /tmp/pip-pip-egg-info-fc762xos\n",
            "    Running command python setup.py egg_info\n",
            "\n",
            "\n",
            "    torch.__version__  = 1.10.0+cu111\n",
            "\n",
            "\n",
            "    running egg_info\n",
            "    creating /tmp/pip-pip-egg-info-fc762xos/apex.egg-info\n",
            "    writing /tmp/pip-pip-egg-info-fc762xos/apex.egg-info/PKG-INFO\n",
            "    writing dependency_links to /tmp/pip-pip-egg-info-fc762xos/apex.egg-info/dependency_links.txt\n",
            "    writing top-level names to /tmp/pip-pip-egg-info-fc762xos/apex.egg-info/top_level.txt\n",
            "    writing manifest file '/tmp/pip-pip-egg-info-fc762xos/apex.egg-info/SOURCES.txt'\n",
            "    adding license file 'LICENSE'\n",
            "    writing manifest file '/tmp/pip-pip-egg-info-fc762xos/apex.egg-info/SOURCES.txt'\n",
            "    /tmp/pip-req-build-6kwr9akf/setup.py:67: UserWarning: Option --pyprof not specified. Not installing PyProf dependencies!\n",
            "      warnings.warn(\"Option --pyprof not specified. Not installing PyProf dependencies!\")\n",
            "  Source in /tmp/pip-req-build-6kwr9akf has version 0.1, which satisfies requirement apex==0.1 from file:///content/apex\n",
            "  Removed apex==0.1 from file:///content/apex from build tracker '/tmp/pip-req-tracker-bfkty70f'\n",
            "Created temporary directory: /tmp/pip-unpack-nbscunxv\n",
            "Skipping wheel build for apex, due to binaries being disabled for it.\n",
            "Installing collected packages: apex\n",
            "  Value for scheme.platlib does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "  distutils: /usr/local/lib/python3.7/dist-packages\n",
            "  sysconfig: /usr/lib/python3.7/site-packages\n",
            "  Value for scheme.purelib does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "  distutils: /usr/local/lib/python3.7/dist-packages\n",
            "  sysconfig: /usr/lib/python3.7/site-packages\n",
            "  Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "  distutils: /usr/local/include/python3.7/apex\n",
            "  sysconfig: /usr/include/python3.7m/apex\n",
            "  Value for scheme.scripts does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "  distutils: /usr/local/bin\n",
            "  sysconfig: /usr/bin\n",
            "  Value for scheme.data does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "  distutils: /usr/local\n",
            "  sysconfig: /usr\n",
            "  Additional context:\n",
            "  user = False\n",
            "  home = None\n",
            "  root = None\n",
            "  prefix = None\n",
            "  Created temporary directory: /tmp/pip-record-urtedwv8\n",
            "    Running command /usr/bin/python3 -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-req-build-6kwr9akf/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-req-build-6kwr9akf/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' --cpp_ext --cuda_ext install --record /tmp/pip-record-urtedwv8/install-record.txt --single-version-externally-managed --compile --install-headers /usr/local/include/python3.7/apex\n",
            "\n",
            "\n",
            "    torch.__version__  = 1.10.0+cu111\n",
            "\n",
            "\n",
            "    /tmp/pip-req-build-6kwr9akf/setup.py:67: UserWarning: Option --pyprof not specified. Not installing PyProf dependencies!\n",
            "      warnings.warn(\"Option --pyprof not specified. Not installing PyProf dependencies!\")\n",
            "\n",
            "    Compiling cuda extensions with\n",
            "    nvcc: NVIDIA (R) Cuda compiler driver\n",
            "    Copyright (c) 2005-2020 NVIDIA Corporation\n",
            "    Built on Mon_Oct_12_20:09:46_PDT_2020\n",
            "    Cuda compilation tools, release 11.1, V11.1.105\n",
            "    Build cuda_11.1.TC455_06.29190527_0\n",
            "    from /usr/local/cuda/bin\n",
            "\n",
            "    running install\n",
            "    running build\n",
            "    running build_py\n",
            "    creating build\n",
            "    creating build/lib.linux-x86_64-3.7\n",
            "    creating build/lib.linux-x86_64-3.7/apex\n",
            "    copying apex/_autocast_utils.py -> build/lib.linux-x86_64-3.7/apex\n",
            "    copying apex/__init__.py -> build/lib.linux-x86_64-3.7/apex\n",
            "    creating build/lib.linux-x86_64-3.7/apex/pyprof\n",
            "    copying apex/pyprof/__init__.py -> build/lib.linux-x86_64-3.7/apex/pyprof\n",
            "    creating build/lib.linux-x86_64-3.7/apex/multi_tensor_apply\n",
            "    copying apex/multi_tensor_apply/multi_tensor_apply.py -> build/lib.linux-x86_64-3.7/apex/multi_tensor_apply\n",
            "    copying apex/multi_tensor_apply/__init__.py -> build/lib.linux-x86_64-3.7/apex/multi_tensor_apply\n",
            "    creating build/lib.linux-x86_64-3.7/apex/transformer\n",
            "    copying apex/transformer/utils.py -> build/lib.linux-x86_64-3.7/apex/transformer\n",
            "    copying apex/transformer/microbatches.py -> build/lib.linux-x86_64-3.7/apex/transformer\n",
            "    copying apex/transformer/parallel_state.py -> build/lib.linux-x86_64-3.7/apex/transformer\n",
            "    copying apex/transformer/enums.py -> build/lib.linux-x86_64-3.7/apex/transformer\n",
            "    copying apex/transformer/log_util.py -> build/lib.linux-x86_64-3.7/apex/transformer\n",
            "    copying apex/transformer/__init__.py -> build/lib.linux-x86_64-3.7/apex/transformer\n",
            "    creating build/lib.linux-x86_64-3.7/apex/reparameterization\n",
            "    copying apex/reparameterization/reparameterization.py -> build/lib.linux-x86_64-3.7/apex/reparameterization\n",
            "    copying apex/reparameterization/__init__.py -> build/lib.linux-x86_64-3.7/apex/reparameterization\n",
            "    copying apex/reparameterization/weight_norm.py -> build/lib.linux-x86_64-3.7/apex/reparameterization\n",
            "    creating build/lib.linux-x86_64-3.7/apex/fused_dense\n",
            "    copying apex/fused_dense/fused_dense.py -> build/lib.linux-x86_64-3.7/apex/fused_dense\n",
            "    copying apex/fused_dense/__init__.py -> build/lib.linux-x86_64-3.7/apex/fused_dense\n",
            "    creating build/lib.linux-x86_64-3.7/apex/optimizers\n",
            "    copying apex/optimizers/fused_sgd.py -> build/lib.linux-x86_64-3.7/apex/optimizers\n",
            "    copying apex/optimizers/fused_mixed_precision_lamb.py -> build/lib.linux-x86_64-3.7/apex/optimizers\n",
            "    copying apex/optimizers/__init__.py -> build/lib.linux-x86_64-3.7/apex/optimizers\n",
            "    copying apex/optimizers/fused_lamb.py -> build/lib.linux-x86_64-3.7/apex/optimizers\n",
            "    copying apex/optimizers/fused_novograd.py -> build/lib.linux-x86_64-3.7/apex/optimizers\n",
            "    copying apex/optimizers/fused_adagrad.py -> build/lib.linux-x86_64-3.7/apex/optimizers\n",
            "    copying apex/optimizers/fused_adam.py -> build/lib.linux-x86_64-3.7/apex/optimizers\n",
            "    creating build/lib.linux-x86_64-3.7/apex/mlp\n",
            "    copying apex/mlp/mlp.py -> build/lib.linux-x86_64-3.7/apex/mlp\n",
            "    copying apex/mlp/__init__.py -> build/lib.linux-x86_64-3.7/apex/mlp\n",
            "    creating build/lib.linux-x86_64-3.7/apex/contrib\n",
            "    copying apex/contrib/__init__.py -> build/lib.linux-x86_64-3.7/apex/contrib\n",
            "    creating build/lib.linux-x86_64-3.7/apex/fp16_utils\n",
            "    copying apex/fp16_utils/fp16util.py -> build/lib.linux-x86_64-3.7/apex/fp16_utils\n",
            "    copying apex/fp16_utils/__init__.py -> build/lib.linux-x86_64-3.7/apex/fp16_utils\n",
            "    copying apex/fp16_utils/fp16_optimizer.py -> build/lib.linux-x86_64-3.7/apex/fp16_utils\n",
            "    copying apex/fp16_utils/loss_scaler.py -> build/lib.linux-x86_64-3.7/apex/fp16_utils\n",
            "    creating build/lib.linux-x86_64-3.7/apex/normalization\n",
            "    copying apex/normalization/fused_layer_norm.py -> build/lib.linux-x86_64-3.7/apex/normalization\n",
            "    copying apex/normalization/__init__.py -> build/lib.linux-x86_64-3.7/apex/normalization\n",
            "    creating build/lib.linux-x86_64-3.7/apex/amp\n",
            "    copying apex/amp/_process_optimizer.py -> build/lib.linux-x86_64-3.7/apex/amp\n",
            "    copying apex/amp/utils.py -> build/lib.linux-x86_64-3.7/apex/amp\n",
            "    copying apex/amp/compat.py -> build/lib.linux-x86_64-3.7/apex/amp\n",
            "    copying apex/amp/wrap.py -> build/lib.linux-x86_64-3.7/apex/amp\n",
            "    copying apex/amp/scaler.py -> build/lib.linux-x86_64-3.7/apex/amp\n",
            "    copying apex/amp/opt.py -> build/lib.linux-x86_64-3.7/apex/amp\n",
            "    copying apex/amp/__version__.py -> build/lib.linux-x86_64-3.7/apex/amp\n",
            "    copying apex/amp/rnn_compat.py -> build/lib.linux-x86_64-3.7/apex/amp\n",
            "    copying apex/amp/_amp_state.py -> build/lib.linux-x86_64-3.7/apex/amp\n",
            "    copying apex/amp/frontend.py -> build/lib.linux-x86_64-3.7/apex/amp\n",
            "    copying apex/amp/__init__.py -> build/lib.linux-x86_64-3.7/apex/amp\n",
            "    copying apex/amp/_initialize.py -> build/lib.linux-x86_64-3.7/apex/amp\n",
            "    copying apex/amp/amp.py -> build/lib.linux-x86_64-3.7/apex/amp\n",
            "    copying apex/amp/handle.py -> build/lib.linux-x86_64-3.7/apex/amp\n",
            "    creating build/lib.linux-x86_64-3.7/apex/parallel\n",
            "    copying apex/parallel/optimized_sync_batchnorm.py -> build/lib.linux-x86_64-3.7/apex/parallel\n",
            "    copying apex/parallel/distributed.py -> build/lib.linux-x86_64-3.7/apex/parallel\n",
            "    copying apex/parallel/optimized_sync_batchnorm_kernel.py -> build/lib.linux-x86_64-3.7/apex/parallel\n",
            "    copying apex/parallel/sync_batchnorm.py -> build/lib.linux-x86_64-3.7/apex/parallel\n",
            "    copying apex/parallel/__init__.py -> build/lib.linux-x86_64-3.7/apex/parallel\n",
            "    copying apex/parallel/LARC.py -> build/lib.linux-x86_64-3.7/apex/parallel\n",
            "    copying apex/parallel/multiproc.py -> build/lib.linux-x86_64-3.7/apex/parallel\n",
            "    copying apex/parallel/sync_batchnorm_kernel.py -> build/lib.linux-x86_64-3.7/apex/parallel\n",
            "    creating build/lib.linux-x86_64-3.7/apex/RNN\n",
            "    copying apex/RNN/cells.py -> build/lib.linux-x86_64-3.7/apex/RNN\n",
            "    copying apex/RNN/RNNBackend.py -> build/lib.linux-x86_64-3.7/apex/RNN\n",
            "    copying apex/RNN/__init__.py -> build/lib.linux-x86_64-3.7/apex/RNN\n",
            "    copying apex/RNN/models.py -> build/lib.linux-x86_64-3.7/apex/RNN\n",
            "    creating build/lib.linux-x86_64-3.7/apex/pyprof/parse\n",
            "    copying apex/pyprof/parse/db.py -> build/lib.linux-x86_64-3.7/apex/pyprof/parse\n",
            "    copying apex/pyprof/parse/__init__.py -> build/lib.linux-x86_64-3.7/apex/pyprof/parse\n",
            "    copying apex/pyprof/parse/nvvp.py -> build/lib.linux-x86_64-3.7/apex/pyprof/parse\n",
            "    copying apex/pyprof/parse/__main__.py -> build/lib.linux-x86_64-3.7/apex/pyprof/parse\n",
            "    copying apex/pyprof/parse/kernel.py -> build/lib.linux-x86_64-3.7/apex/pyprof/parse\n",
            "    copying apex/pyprof/parse/parse.py -> build/lib.linux-x86_64-3.7/apex/pyprof/parse\n",
            "    creating build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/activation.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/pooling.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/index_slice_join_mutate.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/normalization.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/dropout.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/optim.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/recurrentCell.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/pointwise.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/randomSample.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/embedding.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/output.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/convert.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/blas.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/misc.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/base.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/data.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/usage.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/loss.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/__init__.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/__main__.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/linear.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/prof.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/softmax.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/utility.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/conv.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/reduction.py -> build/lib.linux-x86_64-3.7/apex/pyprof/prof\n",
            "    creating build/lib.linux-x86_64-3.7/apex/pyprof/nvtx\n",
            "    copying apex/pyprof/nvtx/nvmarker.py -> build/lib.linux-x86_64-3.7/apex/pyprof/nvtx\n",
            "    copying apex/pyprof/nvtx/__init__.py -> build/lib.linux-x86_64-3.7/apex/pyprof/nvtx\n",
            "    creating build/lib.linux-x86_64-3.7/apex/transformer/functional\n",
            "    copying apex/transformer/functional/__init__.py -> build/lib.linux-x86_64-3.7/apex/transformer/functional\n",
            "    copying apex/transformer/functional/fused_softmax.py -> build/lib.linux-x86_64-3.7/apex/transformer/functional\n",
            "    creating build/lib.linux-x86_64-3.7/apex/transformer/pipeline_parallel\n",
            "    copying apex/transformer/pipeline_parallel/p2p_communication.py -> build/lib.linux-x86_64-3.7/apex/transformer/pipeline_parallel\n",
            "    copying apex/transformer/pipeline_parallel/utils.py -> build/lib.linux-x86_64-3.7/apex/transformer/pipeline_parallel\n",
            "    copying apex/transformer/pipeline_parallel/_timers.py -> build/lib.linux-x86_64-3.7/apex/transformer/pipeline_parallel\n",
            "    copying apex/transformer/pipeline_parallel/__init__.py -> build/lib.linux-x86_64-3.7/apex/transformer/pipeline_parallel\n",
            "    creating build/lib.linux-x86_64-3.7/apex/transformer/testing\n",
            "    copying apex/transformer/testing/standalone_gpt.py -> build/lib.linux-x86_64-3.7/apex/transformer/testing\n",
            "    copying apex/transformer/testing/arguments.py -> build/lib.linux-x86_64-3.7/apex/transformer/testing\n",
            "    copying apex/transformer/testing/commons.py -> build/lib.linux-x86_64-3.7/apex/transformer/testing\n",
            "    copying apex/transformer/testing/__init__.py -> build/lib.linux-x86_64-3.7/apex/transformer/testing\n",
            "    copying apex/transformer/testing/global_vars.py -> build/lib.linux-x86_64-3.7/apex/transformer/testing\n",
            "    copying apex/transformer/testing/standalone_bert.py -> build/lib.linux-x86_64-3.7/apex/transformer/testing\n",
            "    creating build/lib.linux-x86_64-3.7/apex/transformer/amp\n",
            "    copying apex/transformer/amp/__init__.py -> build/lib.linux-x86_64-3.7/apex/transformer/amp\n",
            "    copying apex/transformer/amp/grad_scaler.py -> build/lib.linux-x86_64-3.7/apex/transformer/amp\n",
            "    creating build/lib.linux-x86_64-3.7/apex/transformer/_data\n",
            "    copying apex/transformer/_data/_batchsampler.py -> build/lib.linux-x86_64-3.7/apex/transformer/_data\n",
            "    copying apex/transformer/_data/__init__.py -> build/lib.linux-x86_64-3.7/apex/transformer/_data\n",
            "    creating build/lib.linux-x86_64-3.7/apex/transformer/tensor_parallel\n",
            "    copying apex/transformer/tensor_parallel/layers.py -> build/lib.linux-x86_64-3.7/apex/transformer/tensor_parallel\n",
            "    copying apex/transformer/tensor_parallel/utils.py -> build/lib.linux-x86_64-3.7/apex/transformer/tensor_parallel\n",
            "    copying apex/transformer/tensor_parallel/mappings.py -> build/lib.linux-x86_64-3.7/apex/transformer/tensor_parallel\n",
            "    copying apex/transformer/tensor_parallel/cross_entropy.py -> build/lib.linux-x86_64-3.7/apex/transformer/tensor_parallel\n",
            "    copying apex/transformer/tensor_parallel/data.py -> build/lib.linux-x86_64-3.7/apex/transformer/tensor_parallel\n",
            "    copying apex/transformer/tensor_parallel/random.py -> build/lib.linux-x86_64-3.7/apex/transformer/tensor_parallel\n",
            "    copying apex/transformer/tensor_parallel/__init__.py -> build/lib.linux-x86_64-3.7/apex/transformer/tensor_parallel\n",
            "    copying apex/transformer/tensor_parallel/memory.py -> build/lib.linux-x86_64-3.7/apex/transformer/tensor_parallel\n",
            "    creating build/lib.linux-x86_64-3.7/apex/transformer/pipeline_parallel/schedules\n",
            "    copying apex/transformer/pipeline_parallel/schedules/fwd_bwd_pipelining_without_interleaving.py -> build/lib.linux-x86_64-3.7/apex/transformer/pipeline_parallel/schedules\n",
            "    copying apex/transformer/pipeline_parallel/schedules/__init__.py -> build/lib.linux-x86_64-3.7/apex/transformer/pipeline_parallel/schedules\n",
            "    copying apex/transformer/pipeline_parallel/schedules/fwd_bwd_no_pipelining.py -> build/lib.linux-x86_64-3.7/apex/transformer/pipeline_parallel/schedules\n",
            "    copying apex/transformer/pipeline_parallel/schedules/fwd_bwd_pipelining_with_interleaving.py -> build/lib.linux-x86_64-3.7/apex/transformer/pipeline_parallel/schedules\n",
            "    copying apex/transformer/pipeline_parallel/schedules/common.py -> build/lib.linux-x86_64-3.7/apex/transformer/pipeline_parallel/schedules\n",
            "    creating build/lib.linux-x86_64-3.7/apex/contrib/transducer\n",
            "    copying apex/contrib/transducer/transducer.py -> build/lib.linux-x86_64-3.7/apex/contrib/transducer\n",
            "    copying apex/contrib/transducer/__init__.py -> build/lib.linux-x86_64-3.7/apex/contrib/transducer\n",
            "    creating build/lib.linux-x86_64-3.7/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/distributed_fused_lamb.py -> build/lib.linux-x86_64-3.7/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/fused_sgd.py -> build/lib.linux-x86_64-3.7/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/distributed_fused_adam.py -> build/lib.linux-x86_64-3.7/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/distributed_fused_adam_v2.py -> build/lib.linux-x86_64-3.7/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/__init__.py -> build/lib.linux-x86_64-3.7/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/fused_lamb.py -> build/lib.linux-x86_64-3.7/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/fp16_optimizer.py -> build/lib.linux-x86_64-3.7/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/distributed_fused_adam_v3.py -> build/lib.linux-x86_64-3.7/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/fused_adam.py -> build/lib.linux-x86_64-3.7/apex/contrib/optimizers\n",
            "    creating build/lib.linux-x86_64-3.7/apex/contrib/fmha\n",
            "    copying apex/contrib/fmha/fmha.py -> build/lib.linux-x86_64-3.7/apex/contrib/fmha\n",
            "    copying apex/contrib/fmha/__init__.py -> build/lib.linux-x86_64-3.7/apex/contrib/fmha\n",
            "    creating build/lib.linux-x86_64-3.7/apex/contrib/bottleneck\n",
            "    copying apex/contrib/bottleneck/test.py -> build/lib.linux-x86_64-3.7/apex/contrib/bottleneck\n",
            "    copying apex/contrib/bottleneck/bottleneck_module_test.py -> build/lib.linux-x86_64-3.7/apex/contrib/bottleneck\n",
            "    copying apex/contrib/bottleneck/__init__.py -> build/lib.linux-x86_64-3.7/apex/contrib/bottleneck\n",
            "    copying apex/contrib/bottleneck/bottleneck.py -> build/lib.linux-x86_64-3.7/apex/contrib/bottleneck\n",
            "    creating build/lib.linux-x86_64-3.7/apex/contrib/layer_norm\n",
            "    copying apex/contrib/layer_norm/layer_norm.py -> build/lib.linux-x86_64-3.7/apex/contrib/layer_norm\n",
            "    copying apex/contrib/layer_norm/__init__.py -> build/lib.linux-x86_64-3.7/apex/contrib/layer_norm\n",
            "    creating build/lib.linux-x86_64-3.7/apex/contrib/xentropy\n",
            "    copying apex/contrib/xentropy/softmax_xentropy.py -> build/lib.linux-x86_64-3.7/apex/contrib/xentropy\n",
            "    copying apex/contrib/xentropy/__init__.py -> build/lib.linux-x86_64-3.7/apex/contrib/xentropy\n",
            "    creating build/lib.linux-x86_64-3.7/apex/contrib/sparsity\n",
            "    copying apex/contrib/sparsity/asp.py -> build/lib.linux-x86_64-3.7/apex/contrib/sparsity\n",
            "    copying apex/contrib/sparsity/__init__.py -> build/lib.linux-x86_64-3.7/apex/contrib/sparsity\n",
            "    copying apex/contrib/sparsity/sparse_masklib.py -> build/lib.linux-x86_64-3.7/apex/contrib/sparsity\n",
            "    creating build/lib.linux-x86_64-3.7/apex/contrib/groupbn\n",
            "    copying apex/contrib/groupbn/batch_norm.py -> build/lib.linux-x86_64-3.7/apex/contrib/groupbn\n",
            "    copying apex/contrib/groupbn/__init__.py -> build/lib.linux-x86_64-3.7/apex/contrib/groupbn\n",
            "    creating build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/fast_self_multihead_attn_func.py -> build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/encdec_multihead_attn_func.py -> build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/__init__.py -> build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/mask_softmax_dropout_func.py -> build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/encdec_multihead_attn.py -> build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/self_multihead_attn_func.py -> build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn\n",
            "    copying apex/contrib/multihead_attn/self_multihead_attn.py -> build/lib.linux-x86_64-3.7/apex/contrib/multihead_attn\n",
            "    creating build/lib.linux-x86_64-3.7/apex/amp/lists\n",
            "    copying apex/amp/lists/torch_overrides.py -> build/lib.linux-x86_64-3.7/apex/amp/lists\n",
            "    copying apex/amp/lists/tensor_overrides.py -> build/lib.linux-x86_64-3.7/apex/amp/lists\n",
            "    copying apex/amp/lists/__init__.py -> build/lib.linux-x86_64-3.7/apex/amp/lists\n",
            "    copying apex/amp/lists/functional_overrides.py -> build/lib.linux-x86_64-3.7/apex/amp/lists\n",
            "    running build_ext\n",
            "    /usr/local/lib/python3.7/dist-packages/torch/utils/cpp_extension.py:381: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
            "      warnings.warn(msg.format('we could not find ninja.'))\n",
            "    building 'apex_C' extension\n",
            "    creating build/temp.linux-x86_64-3.7\n",
            "    creating build/temp.linux-x86_64-3.7/csrc\n",
            "    x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fdebug-prefix-map=/build/python3.7-Y7dWVB/python3.7-3.7.12=. -fstack-protector-strong -Wformat -Werror=format-security -g -fdebug-prefix-map=/build/python3.7-Y7dWVB/python3.7-3.7.12=. -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/include/python3.7m -c csrc/flatten_unflatten.cpp -o build/temp.linux-x86_64-3.7/csrc/flatten_unflatten.o -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\"_gcc\" -DPYBIND11_STDLIB=\"_libstdcpp\" -DPYBIND11_BUILD_ABI=\"_cxxabi1011\" -DTORCH_EXTENSION_NAME=apex_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocess GLUE data"
      ],
      "metadata": {
        "id": "eZXxaCaPSt54"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd fairseq\n",
        "!./examples/roberta/preprocess_GLUE_tasks.sh /content/drive/MyDrive/glue_data RTE\n",
        "%cd .."
      ],
      "metadata": {
        "id": "PBo3v5kEyKdr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Finetune RoBERTa"
      ],
      "metadata": {
        "id": "_lZAmfLE37SQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, torchvision.models\n",
        "model = torch.hub.load('pytorch/fairseq', 'roberta.large')\n",
        "path = '/content/drive/MyDrive/roberta.large/model2.pt'\n",
        "torch.save(model.state_dict(), path) # nothing else here\n",
        "# model.load_state_dict(torch.load(path))"
      ],
      "metadata": {
        "id": "f1Y79vIvgtR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd fairseq\n",
        "\n",
        "!TOTAL_NUM_UPDATES=2036\n",
        "!WARMUP_UPDATES=122\n",
        "!LR=2e-05\n",
        "!NUM_CLASSES=2\n",
        "!MAX_SENTENCES=16\n",
        "!ROBERTA_PATH=/content/drive/MyDrive/roberta.large/dict.pth\n",
        "\n",
        "!fairseq-train /content/fairseq/RTE-bin \\\n",
        "    --restore-file /content/drive/MyDrive/roberta.large/model.pt \\\n",
        "    --max-positions 512 \\\n",
        "    --batch-size 16 \\\n",
        "    --max-tokens 4400 \\\n",
        "    --task sentence_prediction \\\n",
        "    --reset-optimizer --reset-dataloader --reset-meters \\\n",
        "    --required-batch-size-multiple 1 \\\n",
        "    --init-token 0 --separator-token 2 \\\n",
        "    --arch roberta_large \\\n",
        "    --criterion sentence_prediction \\\n",
        "    --num-classes 2 \\\n",
        "    --dropout 0.1 --attention-dropout 0.1 \\\n",
        "    --weight-decay 0.1 --optimizer adam --adam-betas \"(0.9, 0.98)\" --adam-eps 1e-06 \\\n",
        "    --clip-norm 0.0 \\\n",
        "    --lr-scheduler polynomial_decay --lr 2e-05 --total-num-update 2036 --warmup-updates 122 \\\n",
        "    --fp16 --fp16-init-scale 4 --threshold-loss-scale 1 --fp16-scale-window 128 \\\n",
        "    --max-epoch 10 \\\n",
        "    --find-unused-parameters \\\n",
        "    --best-checkpoint-metric accuracy --maximize-best-checkpoint-metric \\\n",
        "    --ddp-backend legacy_ddp \\\n",
        "    --quant-noise-pq 0.2 --quant-noise-pq-block-size 8\n",
        "\n",
        "%cd ..\n"
      ],
      "metadata": {
        "id": "NH3slDCy3-is"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!CUDA_VISIBLE_DEVICES=0 fairseq-hydra-train --config-dir /content/fairseq/examples/roberta/config/finetuning --config-name mnli \\\n",
        "task.data=/content/fairseq/MNLI-bin checkpoint.restore_file=$ROBERTA_PATH "
      ],
      "metadata": {
        "id": "3Em1ylWkNQ8V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocess WikiText data"
      ],
      "metadata": {
        "id": "vvOMHIoK43QM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download the data"
      ],
      "metadata": {
        "id": "9phZ7Tjt5Yut"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd fairseq\n",
        "\n",
        "%cd examples/language_model/\n",
        "!bash prepare-wikitext-103.sh\n",
        "%cd ../..\n",
        "\n",
        "%cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MxONDIv_418h",
        "outputId": "65e44907-d726-46b4-b2a9-50e6dd095001"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/fairseq\n",
            "/content/fairseq/examples/language_model\n",
            "--2021-12-12 05:49:18--  https://s3.amazonaws.com/research.metamind.io/wikitext/wikitext-103-v1.zip\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.170.16\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.170.16|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 190229076 (181M) [application/zip]\n",
            "Saving to: ‘wikitext-103-v1.zip’\n",
            "\n",
            "wikitext-103-v1.zip 100%[===================>] 181.42M  33.3MB/s    in 6.1s    \n",
            "\n",
            "2021-12-12 05:49:25 (29.6 MB/s) - ‘wikitext-103-v1.zip’ saved [190229076/190229076]\n",
            "\n",
            "https://s3.amazonaws.com/research.metamind.io/wikitext/wikitext-103-v1.zip successfully downloaded.\n",
            "Archive:  wikitext-103-v1.zip\n",
            "   creating: wikitext-103/\n",
            "  inflating: wikitext-103/wiki.test.tokens  \n",
            "  inflating: wikitext-103/wiki.valid.tokens  \n",
            "  inflating: wikitext-103/wiki.train.tokens  \n",
            "/content/fairseq\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocess the data"
      ],
      "metadata": {
        "id": "KniHy6KI6s4X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd fairseq\n",
        "\n",
        "!TEXT=examples/language_model/wikitext-103; \\\n",
        " fairseq-preprocess \\\n",
        "    --only-source \\\n",
        "    --trainpref $TEXT/wiki.train.tokens \\\n",
        "    --validpref $TEXT/wiki.valid.tokens \\\n",
        "    --testpref $TEXT/wiki.test.tokens \\\n",
        "    --destdir data-bin/wikitext-103 \\\n",
        "    --workers 20\n",
        "\n",
        "%cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxNYTg4t5jMT",
        "outputId": "4f4ed379-71be-49ec-8654-4fc418d8286c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/fairseq\n",
            "2021-12-12 05:52:20 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, azureml_logging=False, bf16=False, bpe=None, cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='data-bin/wikitext-103', dict_only=False, empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_file=None, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, on_cpu_convert_precision=False, only_source=True, optimizer=None, padding_factor=8, plasma_path='/tmp/plasma', profile=False, quantization_config_path=None, reset_logging=False, scoring='bleu', seed=1, source_lang=None, srcdict=None, suppress_crashes=False, target_lang=None, task='translation', tensorboard_logdir=None, testpref='examples/language_model/wikitext-103/wiki.test.tokens', tgtdict=None, threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref='examples/language_model/wikitext-103/wiki.train.tokens', use_plasma_view=False, user_dir=None, validpref='examples/language_model/wikitext-103/wiki.valid.tokens', wandb_project=None, workers=20)\n",
            "2021-12-12 05:55:21 | INFO | fairseq_cli.preprocess | [None] Dictionary: 267744 types\n",
            "2021-12-12 06:02:17 | INFO | fairseq_cli.preprocess | [None] examples/language_model/wikitext-103/wiki.train.tokens: 1801350 sents, 103227021 tokens, 0.0% replaced by <unk>\n",
            "2021-12-12 06:02:17 | INFO | fairseq_cli.preprocess | [None] Dictionary: 267744 types\n",
            "2021-12-12 06:02:22 | INFO | fairseq_cli.preprocess | [None] examples/language_model/wikitext-103/wiki.valid.tokens: 3760 sents, 217646 tokens, 0.0% replaced by <unk>\n",
            "2021-12-12 06:02:22 | INFO | fairseq_cli.preprocess | [None] Dictionary: 267744 types\n",
            "2021-12-12 06:02:27 | INFO | fairseq_cli.preprocess | [None] examples/language_model/wikitext-103/wiki.test.tokens: 4358 sents, 245569 tokens, 0.0% replaced by <unk>\n",
            "2021-12-12 06:02:27 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to data-bin/wikitext-103\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model with noise"
      ],
      "metadata": {
        "id": "6tbB_vZ26wrj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd fairseq\n",
        "\n",
        "!fairseq-train --task language_modeling data-bin/wikitext-103  \\\n",
        "    --save-dir /content/drive/MyDrive/checkpoints/transformer_wikitext-103 \\\n",
        "    --adaptive-input --adaptive-input-cutoff 20000,60000 --adaptive-input-factor 4 \\\n",
        "    --adaptive-softmax-cutoff 20000,60000 --adaptive-softmax-dropout 0.2 --adaptive-softmax-factor 4.0 \\\n",
        "    --tie-adaptive-proj --tie-adaptive-weights \\\n",
        "    --arch transformer_lm_gbw \\\n",
        "    --attention-dropout 0.1 --dropout 0.2 --relu-dropout 0.1 \\\n",
        "    --clip-norm 0.1 --criterion adaptive_loss \\\n",
        "    --ddp-backend legacy_ddp \\\n",
        "    --decoder-attention-heads 8 --decoder-embed-dim 1024 --decoder-ffn-embed-dim 4096 --decoder-input-dim 1024 \\\n",
        "    --decoder-layers 16 --decoder-normalize-before --decoder-output-dim 1024 \\\n",
        "    --min-lr 0.0001 --lr-period-updates 270000 --lr-scheduler cosine --lr-shrink 0.75 --lr 1.0 --t-mult 2.0 \\\n",
        "    --max-tokens 3072 --tokens-per-sample 1024 --momentum 0.99 --optimizer nag \\\n",
        "    --sample-break-mode none --update-freq 3 \\\n",
        "    --warmup-init-lr 1e-07 --warmup-updates 16000 \\\n",
        "    --weight-decay 0 --seed 1 --stop-min-lr 1e-09 \\\n",
        "    --quant-noise-pq 0.05 --quant-noise-pq-block-size 8\n",
        "\n",
        "%cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xUNzP_Y97iK3",
        "outputId": "e4e6df1c-496c-40b9-be99-0745635cc5ae"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/fairseq\n",
            "2021-12-12 06:09:55 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 3072, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 3072, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.1, 'sentence_avg': False, 'update_freq': [3], 'lr': [1.0], 'stop_min_lr': 1e-09, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/content/drive/MyDrive/checkpoints/transformer_wikitext-103', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'transformer_lm_gbw', 'activation_fn': 'relu', 'dropout': 0.2, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'relu_dropout': 0.1, 'decoder_embed_dim': 1024, 'decoder_output_dim': 1024, 'decoder_input_dim': 1024, 'decoder_ffn_embed_dim': 4096, 'decoder_layers': 16, 'decoder_attention_heads': 8, 'decoder_normalize_before': True, 'no_decoder_final_norm': True, 'adaptive_softmax_cutoff': '20000,60000', 'adaptive_softmax_dropout': 0.2, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': False, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': True, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': '20000,60000', 'tie_adaptive_weights': True, 'tie_adaptive_proj': True, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': False, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.05, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 0, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 1024, 'max_target_positions': None, 'tpu': False}, 'task': {'_name': 'language_modeling', 'data': 'data-bin/wikitext-103', 'sample_break_mode': 'none', 'tokens_per_sample': 1024, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 1, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'criterion': {'_name': 'adaptive_loss', 'sentence_avg': False, 'ddp_backend': 'legacy_ddp'}, 'optimizer': {'_name': 'nag', 'momentum': 0.99, 'weight_decay': 0.0, 'lr': [1.0]}, 'lr_scheduler': {'_name': 'cosine', 'warmup_updates': 16000, 'warmup_init_lr': 1e-07, 'lr': [1.0], 'min_lr': 0.0001, 't_mult': 2.0, 'lr_period_updates': 270000.0, 'lr_shrink': 0.75, 'max_update': 0}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
            "2021-12-12 06:09:55 | INFO | fairseq.tasks.language_modeling | dictionary: 267744 types\n",
            "2021-12-12 06:09:58 | INFO | fairseq_cli.train | TransformerLanguageModel(\n",
            "  (decoder): TransformerDecoder(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_tokens): AdaptiveInput(\n",
            "      (embeddings): ModuleList(\n",
            "        (0): Sequential(\n",
            "          (0): Embedding(20000, 1024, padding_idx=1)\n",
            "          (1): Linear(in_features=1024, out_features=1024, bias=False)\n",
            "        )\n",
            "        (1): Sequential(\n",
            "          (0): Embedding(40000, 256)\n",
            "          (1): Linear(in_features=256, out_features=1024, bias=False)\n",
            "        )\n",
            "        (2): Sequential(\n",
            "          (0): Embedding(207744, 64)\n",
            "          (1): Linear(in_features=64, out_features=1024, bias=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (layers): ModuleList(\n",
            "      (0): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (1): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (2): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (3): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (4): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (5): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (6): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (7): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (8): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (9): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (10): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (11): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (12): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (13): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (14): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (15): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (adaptive_softmax): AdaptiveSoftmax(\n",
            "      (dropout_module): FairseqDropout()\n",
            "      (lsm): LogSoftmax(dim=1)\n",
            "      (head): TiedHeadModule(\n",
            "        (word_proj): TiedLinear()\n",
            "        (class_proj): Linear(in_features=1024, out_features=2, bias=False)\n",
            "      )\n",
            "      (tail): ModuleList(\n",
            "        (0): Sequential(\n",
            "          (0): TiedLinear()\n",
            "          (1): Dropout(p=0.2, inplace=False)\n",
            "          (2): TiedLinear()\n",
            "        )\n",
            "        (1): Sequential(\n",
            "          (0): TiedLinear()\n",
            "          (1): Dropout(p=0.2, inplace=False)\n",
            "          (2): TiedLinear()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "2021-12-12 06:09:58 | INFO | fairseq_cli.train | task: LanguageModelingTask\n",
            "2021-12-12 06:09:58 | INFO | fairseq_cli.train | model: TransformerLanguageModel\n",
            "2021-12-12 06:09:58 | INFO | fairseq_cli.train | criterion: AdaptiveLoss\n",
            "2021-12-12 06:09:58 | INFO | fairseq_cli.train | num. shared model params: 246,933,504 (num. trained: 246,933,504)\n",
            "2021-12-12 06:09:58 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)\n",
            "2021-12-12 06:09:58 | INFO | fairseq.data.data_utils | loaded 3,760 examples from: data-bin/wikitext-103/valid\n",
            "2021-12-12 06:10:06 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.embeddings.0.0.weight <- decoder.adaptive_softmax.head.word_proj.weight\n",
            "2021-12-12 06:10:06 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.embeddings.0.1.bias <- decoder.embed_tokens.embeddings.1.1.bias\n",
            "2021-12-12 06:10:06 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.embeddings.0.1.bias <- decoder.embed_tokens.embeddings.2.1.bias\n",
            "2021-12-12 06:10:06 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.embeddings.0.1.bias <- decoder.adaptive_softmax.head.class_proj.bias\n",
            "2021-12-12 06:10:06 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.embeddings.1.0.weight <- decoder.adaptive_softmax.tail.0.2.weight\n",
            "2021-12-12 06:10:06 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.embeddings.1.1.weight <- decoder.adaptive_softmax.tail.0.0.weight\n",
            "2021-12-12 06:10:06 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.embeddings.2.0.weight <- decoder.adaptive_softmax.tail.1.2.weight\n",
            "2021-12-12 06:10:06 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.embeddings.2.1.weight <- decoder.adaptive_softmax.tail.1.0.weight\n",
            "2021-12-12 06:10:06 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2021-12-12 06:10:06 | INFO | fairseq.utils | rank   0: capabilities =  6.0  ; total memory = 15.899 GB ; name = Tesla P100-PCIE-16GB                    \n",
            "2021-12-12 06:10:06 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2021-12-12 06:10:06 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
            "2021-12-12 06:10:06 | INFO | fairseq_cli.train | max tokens per device = 3072 and max sentences per device = None\n",
            "2021-12-12 06:10:06 | INFO | fairseq.trainer | Preparing to load checkpoint /content/drive/MyDrive/checkpoints/transformer_wikitext-103/checkpoint_last.pt\n",
            "2021-12-12 06:10:06 | INFO | fairseq.trainer | No existing checkpoint found /content/drive/MyDrive/checkpoints/transformer_wikitext-103/checkpoint_last.pt\n",
            "2021-12-12 06:10:06 | INFO | fairseq.trainer | loading train data for epoch 1\n",
            "2021-12-12 06:10:06 | INFO | fairseq.data.data_utils | loaded 1,801,350 examples from: data-bin/wikitext-103/train\n",
            "2021-12-12 06:10:07 | INFO | fairseq.data.iterators | grouped total_num_itrs = 11201\n",
            "epoch 001:   0% 0/11201 [00:00<?, ?it/s]2021-12-12 06:10:07 | INFO | fairseq.trainer | begin training epoch 1\n",
            "2021-12-12 06:10:07 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 001: 100% 11200/11201 [7:24:39<00:02,  2.38s/it, loss=15845.8, ppl=inf, wps=3864.6, ups=0.42, wpb=9216, bsz=9, num_updates=11200, lr=0.7, gnorm=3.97606e+06, clip=100, train_wall=238, gb_free=3.9, wall=26680]    2021-12-12 13:34:49 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:   0% 0/71 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:   1% 1/71 [00:00<00:23,  3.03it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:   3% 2/71 [00:00<00:19,  3.46it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:   4% 3/71 [00:00<00:18,  3.63it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:   6% 4/71 [00:01<00:18,  3.71it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:   7% 5/71 [00:01<00:17,  3.75it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:   8% 6/71 [00:01<00:17,  3.79it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  10% 7/71 [00:01<00:16,  3.80it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  11% 8/71 [00:02<00:16,  3.81it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  13% 9/71 [00:02<00:16,  3.82it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  14% 10/71 [00:02<00:15,  3.83it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  15% 11/71 [00:02<00:15,  3.83it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  17% 12/71 [00:03<00:15,  3.83it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  18% 13/71 [00:03<00:15,  3.83it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  20% 14/71 [00:03<00:14,  3.83it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  21% 15/71 [00:03<00:14,  3.82it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  23% 16/71 [00:04<00:14,  3.83it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  24% 17/71 [00:04<00:14,  3.84it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  25% 18/71 [00:04<00:13,  3.84it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  27% 19/71 [00:05<00:13,  3.84it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  28% 20/71 [00:05<00:13,  3.84it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  30% 21/71 [00:05<00:13,  3.84it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  31% 22/71 [00:05<00:12,  3.84it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  32% 23/71 [00:06<00:12,  3.85it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  34% 24/71 [00:06<00:12,  3.84it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  35% 25/71 [00:06<00:11,  3.84it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  37% 26/71 [00:06<00:11,  3.85it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  38% 27/71 [00:07<00:11,  3.84it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  39% 28/71 [00:07<00:11,  3.84it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  41% 29/71 [00:07<00:10,  3.84it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  42% 30/71 [00:07<00:10,  3.85it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  44% 31/71 [00:08<00:10,  3.84it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  45% 32/71 [00:08<00:10,  3.83it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  46% 33/71 [00:08<00:09,  3.84it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  48% 34/71 [00:08<00:09,  3.84it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  49% 35/71 [00:09<00:09,  3.84it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  51% 36/71 [00:09<00:09,  3.84it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  52% 37/71 [00:09<00:08,  3.82it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  54% 38/71 [00:09<00:08,  3.83it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  55% 39/71 [00:10<00:08,  3.83it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  56% 40/71 [00:10<00:08,  3.83it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  58% 41/71 [00:10<00:07,  3.83it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  59% 42/71 [00:11<00:07,  3.84it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  61% 43/71 [00:11<00:07,  3.84it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  62% 44/71 [00:11<00:07,  3.84it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  63% 45/71 [00:11<00:06,  3.85it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  65% 46/71 [00:12<00:06,  3.85it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  66% 47/71 [00:12<00:06,  3.82it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  68% 48/71 [00:12<00:06,  3.83it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  69% 49/71 [00:12<00:05,  3.83it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  70% 50/71 [00:13<00:05,  3.84it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  72% 51/71 [00:13<00:05,  3.84it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  73% 52/71 [00:13<00:04,  3.84it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  75% 53/71 [00:13<00:04,  3.85it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  76% 54/71 [00:14<00:04,  3.85it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  77% 55/71 [00:14<00:04,  3.85it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  79% 56/71 [00:14<00:03,  3.85it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  80% 57/71 [00:14<00:03,  3.85it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  82% 58/71 [00:15<00:03,  3.84it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  83% 59/71 [00:15<00:03,  3.85it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  85% 60/71 [00:15<00:02,  3.85it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  86% 61/71 [00:15<00:02,  3.85it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  87% 62/71 [00:16<00:02,  3.87it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  89% 63/71 [00:16<00:02,  3.87it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  90% 64/71 [00:16<00:01,  3.88it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  92% 65/71 [00:16<00:01,  3.88it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  93% 66/71 [00:17<00:01,  3.88it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  94% 67/71 [00:17<00:01,  3.88it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  96% 68/71 [00:17<00:00,  3.88it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  97% 69/71 [00:18<00:00,  3.88it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  99% 70/71 [00:18<00:00,  3.89it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset: 100% 71/71 [00:18<00:00,  3.89it/s]\u001b[A\n",
            "                                                                        \u001b[A2021-12-12 13:35:07 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 31016.7 | ppl inf | wps 11817 | wpb 3065.4 | bsz 3 | num_updates 11201\n",
            "2021-12-12 13:35:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 11201 updates\n",
            "2021-12-12 13:35:07 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/checkpoints/transformer_wikitext-103/checkpoint1.pt\n",
            "2021-12-12 13:35:19 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/checkpoints/transformer_wikitext-103/checkpoint1.pt\n",
            "2021-12-12 13:36:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/checkpoints/transformer_wikitext-103/checkpoint1.pt (epoch 1 @ 11201 updates, score 31016.664) (writing took 61.29464115600058 seconds)\n",
            "2021-12-12 13:36:08 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)\n",
            "2021-12-12 13:36:08 | INFO | train | epoch 001 | loss 731442 | ppl inf | wps 3857.4 | ups 0.42 | wpb 9215.9 | bsz 9 | num_updates 11201 | lr 0.700063 | gnorm 1.75954e+07 | clip 100 | train_wall 26643 | gb_free 3.9 | wall 26762\n",
            "2021-12-12 13:36:09 | INFO | fairseq.data.iterators | grouped total_num_itrs = 11201\n",
            "epoch 002:   0% 0/11201 [00:00<?, ?it/s]2021-12-12 13:36:09 | INFO | fairseq.trainer | begin training epoch 2\n",
            "2021-12-12 13:36:09 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 002: 100% 11200/11201 [7:25:19<00:02,  2.38s/it, loss=87475.4, ppl=inf, wps=3861.9, ups=0.42, wpb=9216, bsz=9, num_updates=22400, lr=0.998614, gnorm=435108, clip=100, train_wall=238, gb_free=3.9, wall=53479]2021-12-12 21:01:30 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:   0% 0/71 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:   1% 1/71 [00:00<00:24,  2.91it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:   3% 2/71 [00:00<00:20,  3.39it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:   4% 3/71 [00:00<00:18,  3.59it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:   6% 4/71 [00:01<00:18,  3.69it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:   7% 5/71 [00:01<00:17,  3.74it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:   8% 6/71 [00:01<00:17,  3.77it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  10% 7/71 [00:01<00:16,  3.79it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  11% 8/71 [00:02<00:16,  3.80it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  13% 9/71 [00:02<00:16,  3.81it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  14% 10/71 [00:02<00:15,  3.82it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  15% 11/71 [00:02<00:15,  3.83it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  17% 12/71 [00:03<00:15,  3.83it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  18% 13/71 [00:03<00:15,  3.84it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  20% 14/71 [00:03<00:14,  3.82it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  21% 15/71 [00:03<00:14,  3.83it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  23% 16/71 [00:04<00:14,  3.83it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  24% 17/71 [00:04<00:14,  3.83it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  25% 18/71 [00:04<00:13,  3.82it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  27% 19/71 [00:05<00:13,  3.82it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  28% 20/71 [00:05<00:13,  3.82it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  30% 21/71 [00:05<00:13,  3.83it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  31% 22/71 [00:05<00:12,  3.83it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  32% 23/71 [00:06<00:12,  3.83it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  34% 24/71 [00:06<00:12,  3.83it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  35% 25/71 [00:06<00:12,  3.83it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  37% 26/71 [00:06<00:11,  3.83it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  38% 27/71 [00:07<00:11,  3.84it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  39% 28/71 [00:07<00:11,  3.84it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  41% 29/71 [00:07<00:10,  3.84it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  42% 30/71 [00:07<00:10,  3.85it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  44% 31/71 [00:08<00:10,  3.85it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  45% 32/71 [00:08<00:10,  3.85it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  46% 33/71 [00:08<00:09,  3.85it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  48% 34/71 [00:08<00:09,  3.85it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  49% 35/71 [00:09<00:09,  3.85it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  51% 36/71 [00:09<00:09,  3.85it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  52% 37/71 [00:09<00:08,  3.84it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  54% 38/71 [00:09<00:08,  3.84it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  55% 39/71 [00:10<00:08,  3.84it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  56% 40/71 [00:10<00:08,  3.84it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  58% 41/71 [00:10<00:07,  3.83it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  59% 42/71 [00:11<00:07,  3.84it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  61% 43/71 [00:11<00:07,  3.84it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  62% 44/71 [00:11<00:07,  3.84it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  63% 45/71 [00:11<00:06,  3.84it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  65% 46/71 [00:12<00:06,  3.84it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  66% 47/71 [00:12<00:06,  3.84it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  68% 48/71 [00:12<00:05,  3.84it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  69% 49/71 [00:12<00:05,  3.83it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  70% 50/71 [00:13<00:05,  3.83it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  72% 51/71 [00:13<00:05,  3.82it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  73% 52/71 [00:13<00:04,  3.82it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  75% 53/71 [00:13<00:04,  3.83it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  76% 54/71 [00:14<00:04,  3.83it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  77% 55/71 [00:14<00:04,  3.83it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  79% 56/71 [00:14<00:03,  3.83it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  80% 57/71 [00:14<00:03,  3.83it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  82% 58/71 [00:15<00:03,  3.83it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  83% 59/71 [00:15<00:03,  3.84it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  85% 60/71 [00:15<00:02,  3.86it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  86% 61/71 [00:15<00:02,  3.85it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  87% 62/71 [00:16<00:02,  3.87it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  89% 63/71 [00:16<00:02,  3.87it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  90% 64/71 [00:16<00:01,  3.88it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  92% 65/71 [00:17<00:01,  3.88it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  93% 66/71 [00:17<00:01,  3.87it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  94% 67/71 [00:17<00:01,  3.87it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  96% 68/71 [00:17<00:00,  3.88it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  97% 69/71 [00:18<00:00,  3.88it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  99% 70/71 [00:18<00:00,  3.88it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset: 100% 71/71 [00:18<00:00,  3.89it/s]\u001b[A\n",
            "                                                                        \u001b[A2021-12-12 21:01:49 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 17749 | ppl inf | wps 11806.8 | wpb 3065.4 | bsz 3 | num_updates 22402 | best_loss 17749\n",
            "2021-12-12 21:01:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 22402 updates\n",
            "2021-12-12 21:01:49 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/checkpoints/transformer_wikitext-103/checkpoint2.pt\n",
            "2021-12-12 21:02:02 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/checkpoints/transformer_wikitext-103/checkpoint2.pt\n",
            "2021-12-12 21:02:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/checkpoints/transformer_wikitext-103/checkpoint2.pt (epoch 2 @ 22402 updates, score 17748.951) (writing took 61.78505180799402 seconds)\n",
            "2021-12-12 21:02:50 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)\n",
            "2021-12-12 21:02:50 | INFO | train | epoch 002 | loss 2.61806e+08 | ppl inf | wps 3851.5 | ups 0.42 | wpb 9215.9 | bsz 9 | num_updates 22402 | lr 0.998614 | gnorm 4.44438e+08 | clip 100 | train_wall 26681 | gb_free 3.9 | wall 53564\n",
            "2021-12-12 21:02:51 | INFO | fairseq.data.iterators | grouped total_num_itrs = 11201\n",
            "epoch 003:   0% 0/11201 [00:00<?, ?it/s]2021-12-12 21:02:51 | INFO | fairseq.trainer | begin training epoch 3\n",
            "2021-12-12 21:02:51 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/fairseq-train\", line 33, in <module>\n",
            "    sys.exit(load_entry_point('fairseq', 'console_scripts', 'fairseq-train')())\n",
            "  File \"/content/fairseq/fairseq_cli/train.py\", line 528, in cli_main\n",
            "    distributed_utils.call_main(cfg, main)\n",
            "  File \"/content/fairseq/fairseq/distributed/utils.py\", line 369, in call_main\n",
            "    main(cfg, **kwargs)\n",
            "  File \"/content/fairseq/fairseq_cli/train.py\", line 188, in main\n",
            "    valid_losses, should_stop = train(cfg, trainer, task, epoch_itr)\n",
            "  File \"/usr/lib/python3.7/contextlib.py\", line 74, in inner\n",
            "    return func(*args, **kwds)\n",
            "  File \"/content/fairseq/fairseq_cli/train.py\", line 303, in train\n",
            "    log_output = trainer.train_step(samples)\n",
            "  File \"/usr/lib/python3.7/contextlib.py\", line 74, in inner\n",
            "    return func(*args, **kwds)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 767, in train_step\n",
            "    **extra_kwargs,\n",
            "  File \"/content/fairseq/fairseq/tasks/fairseq_task.py\", line 516, in train_step\n",
            "    optimizer.backward(loss)\n",
            "  File \"/content/fairseq/fairseq/optim/fairseq_optimizer.py\", line 95, in backward\n",
            "    loss.backward()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\", line 307, in backward\n",
            "    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\", line 156, in backward\n",
            "    allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
            "KeyboardInterrupt\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate the model"
      ],
      "metadata": {
        "id": "iEgLSXrU-0Jv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd fairseq\n",
        "\n",
        "!fairseq-eval-lm data-bin/wikitext-103 --path /content/drive/MyDrive/checkpoints/transformer_wikitext-103/checkpoint_last.pt \\\n",
        "    --sample-break-mode complete \\\n",
        "    --max-tokens 1024 \\\n",
        "    --context-window 2560 \\\n",
        "    --softmax-batch 1024 \\\n",
        "    --gen-subset test\n",
        "\n",
        "%cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9YWGEep-2do",
        "outputId": "4a11e158-9f98-463e-b7d9-5fd190b7f716"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/fairseq\n",
            "2021-12-12 23:37:10 | INFO | fairseq_cli.eval_lm | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': '/content/drive/MyDrive/checkpoints/transformer_wikitext-103/checkpoint_last.pt', 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 1024, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 1024, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 2560, 'softmax_batch': 1024}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': None, 'task': {'_name': 'language_modeling', 'data': 'data-bin/wikitext-103', 'sample_break_mode': 'complete', 'tokens_per_sample': 1024, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 1, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
            "2021-12-12 23:37:11 | INFO | fairseq.tasks.language_modeling | dictionary: 267744 types\n",
            "2021-12-12 23:37:11 | INFO | fairseq_cli.eval_lm | loading model(s) from /content/drive/MyDrive/checkpoints/transformer_wikitext-103/checkpoint_last.pt\n",
            "2021-12-12 23:37:38 | INFO | fairseq_cli.eval_lm | num. model params: 246,933,504\n",
            "2021-12-12 23:37:38 | INFO | fairseq.data.data_utils | loaded 4,358 examples from: data-bin/wikitext-103/test\n",
            "2021-12-12 23:37:38 | INFO | fairseq_cli.eval_lm | data-bin/wikitext-103 test 4,358 examples\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/fairseq-eval-lm\", line 33, in <module>\n",
            "    sys.exit(load_entry_point('fairseq', 'console_scripts', 'fairseq-eval-lm')())\n",
            "  File \"/content/fairseq/fairseq_cli/eval_lm.py\", line 343, in cli_main\n",
            "    distributed_utils.call_main(convert_namespace_to_omegaconf(args), main)\n",
            "  File \"/content/fairseq/fairseq/distributed/utils.py\", line 369, in call_main\n",
            "    main(cfg, **kwargs)\n",
            "  File \"/content/fairseq/fairseq_cli/eval_lm.py\", line 327, in main\n",
            "    remove_bos_token=getattr(cfg.task, \"add_bos_token\", False),\n",
            "  File \"/content/fairseq/fairseq_cli/eval_lm.py\", line 114, in eval_lm\n",
            "    hypos = scorer.generate(models, sample)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/content/fairseq/fairseq/sequence_scorer.py\", line 68, in generate\n",
            "    decoder_out = model(**net_input)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/content/fairseq/fairseq/models/fairseq_model.py\", line 501, in forward\n",
            "    return self.decoder(src_tokens, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/content/fairseq/fairseq/models/transformer/transformer_decoder.py\", line 222, in forward\n",
            "    alignment_heads=alignment_heads,\n",
            "  File \"/content/fairseq/fairseq/models/transformer/transformer_decoder.py\", line 244, in extract_features\n",
            "    alignment_heads,\n",
            "  File \"/content/fairseq/fairseq/models/transformer/transformer_decoder.py\", line 348, in extract_features_scriptable\n",
            "    need_head_weights=bool((idx == alignment_layer)),\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/content/fairseq/fairseq/modules/transformer_layer.py\", line 394, in forward\n",
            "    attn_mask=self_attn_mask,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/content/fairseq/fairseq/modules/multihead_attention.py\", line 191, in forward\n",
            "    v_proj_weight=self.v_proj.weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\", line 5101, in multi_head_attention_forward\n",
            "    attn_output, attn_output_weights = _scaled_dot_product_attention(q, k, v, attn_mask, dropout_p)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\", line 4844, in _scaled_dot_product_attention\n",
            "    attn = torch.bmm(q, k.transpose(-2, -1))\n",
            "RuntimeError: CUDA out of memory. Tried to allocate 6.13 GiB (GPU 0; 15.90 GiB total capacity; 9.23 GiB already allocated; 5.12 GiB free; 9.79 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Quantize the model"
      ],
      "metadata": {
        "id": "Q0H0Nym-_X1g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd fairseq\n",
        "\n",
        "!fairseq-train --task language_modeling data-bin/wikitext-103 \\\n",
        "    --save-dir /content/drive/MyDrive/checkpoints/transformer_wikitext-103-quantized \\\n",
        "    --adaptive-input --adaptive-input-cutoff 20000,60000 --adaptive-input-factor 4 \\\n",
        "    --adaptive-softmax-cutoff 20000,60000 --adaptive-softmax-dropout 0.2 --adaptive-softmax-factor 4.0 \\\n",
        "    --arch transformer_lm_gbw \\\n",
        "    --attention-dropout 0.1 --dropout 0.2 --relu-dropout 0.1  \\\n",
        "    --bucket-cap-mb 25 --char-embedder-highway-layers 2 --character-embedding-dim 4 \\\n",
        "    --clip-norm 0.1 --criterion adaptive_loss \\\n",
        "    --ddp-backend legacy_ddp \\\n",
        "    --decoder-attention-heads 8 --decoder-embed-dim 1024 --decoder-ffn-embed-dim 4096 --decoder-input-dim 1024 --decoder-layers 16 --decoder-normalize-before --decoder-output-dim 1024 \\\n",
        "    --fp16 --keep-last-epochs -1 \\\n",
        "    --min-lr 0.0001 --lr-period-updates 270000 --lr-scheduler cosine --lr-shrink 0.75 --lr 0.05 --stop-min-lr 1e-09 \\\n",
        "    --max-tokens 2944  --tokens-per-sample 2944\\\n",
        "    --momentum 0.99 --no-epoch-checkpoints --no-progress-bar --optimizer nag --required-batch-size-multiple 8 \\\n",
        "    --sample-break-mode none --t-mult 2.0 --skip-invalid-size-inputs-valid-test \\\n",
        "    --tie-adaptive-proj --tie-adaptive-weights --update-freq 3 --weight-decay 0 --seed 1  \\\n",
        "    --log-interval 100 --no-progress-bar --skip-invalid-size-inputs-valid-test \\\n",
        "    --restore-file /content/drive/MyDrive/checkpoints/transformer_wikitext-103/checkpoint_best.pt \\\n",
        "    --max-update 13500 --quantization-config-path examples/quant_noise/transformer_quantization_config.yaml\n",
        "\n",
        "%cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m42-9GG3_IXL",
        "outputId": "eebbdd9a-9ce2-4fc7-f96f-1518a812b8a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/fairseq\n",
            "2021-12-12 23:39:20 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': 'examples/quant_noise/transformer_quantization_config.yaml', 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 2944, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 2944, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 13500, 'stop_time_hours': 0.0, 'clip_norm': 0.1, 'sentence_avg': False, 'update_freq': [3], 'lr': [0.05], 'stop_min_lr': 1e-09, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/content/drive/MyDrive/checkpoints/transformer_wikitext-103-quantized', 'restore_file': '/content/drive/MyDrive/checkpoints/transformer_wikitext-103/checkpoint_best.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'transformer_lm_gbw', 'activation_fn': 'relu', 'dropout': 0.2, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'relu_dropout': 0.1, 'decoder_embed_dim': 1024, 'decoder_output_dim': 1024, 'decoder_input_dim': 1024, 'decoder_ffn_embed_dim': 4096, 'decoder_layers': 16, 'decoder_attention_heads': 8, 'decoder_normalize_before': True, 'no_decoder_final_norm': True, 'adaptive_softmax_cutoff': '20000,60000', 'adaptive_softmax_dropout': 0.2, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': False, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': True, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': '20000,60000', 'tie_adaptive_weights': True, 'tie_adaptive_proj': True, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': False, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 0, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 2944, 'max_target_positions': None, 'tpu': False}, 'task': {'_name': 'language_modeling', 'data': 'data-bin/wikitext-103', 'sample_break_mode': 'none', 'tokens_per_sample': 2944, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 1, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'criterion': {'_name': 'adaptive_loss', 'sentence_avg': False, 'ddp_backend': 'legacy_ddp'}, 'optimizer': {'_name': 'nag', 'momentum': 0.99, 'weight_decay': 0.0, 'lr': [0.05]}, 'lr_scheduler': {'_name': 'cosine', 'warmup_updates': 0, 'warmup_init_lr': -1.0, 'lr': [0.05], 'min_lr': 0.0001, 't_mult': 2.0, 'lr_period_updates': 270000.0, 'lr_shrink': 0.75, 'max_update': 13500}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
            "2021-12-12 23:39:21 | INFO | fairseq.tasks.language_modeling | dictionary: 267744 types\n",
            "2021-12-12 23:39:24 | INFO | fairseq_cli.train | TransformerLanguageModel(\n",
            "  (decoder): TransformerDecoder(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_tokens): AdaptiveInput(\n",
            "      (embeddings): ModuleList(\n",
            "        (0): Sequential(\n",
            "          (0): Embedding(20000, 1024, padding_idx=1)\n",
            "          (1): Linear(in_features=1024, out_features=1024, bias=False)\n",
            "        )\n",
            "        (1): Sequential(\n",
            "          (0): Embedding(40000, 256)\n",
            "          (1): Linear(in_features=256, out_features=1024, bias=False)\n",
            "        )\n",
            "        (2): Sequential(\n",
            "          (0): Embedding(207744, 64)\n",
            "          (1): Linear(in_features=64, out_features=1024, bias=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (layers): ModuleList(\n",
            "      (0): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (1): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (2): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (3): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (4): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (5): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (6): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (7): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (8): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (9): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (10): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (11): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (12): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (13): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (14): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (15): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (adaptive_softmax): AdaptiveSoftmax(\n",
            "      (dropout_module): FairseqDropout()\n",
            "      (lsm): LogSoftmax(dim=1)\n",
            "      (head): TiedHeadModule(\n",
            "        (word_proj): TiedLinear()\n",
            "        (class_proj): Linear(in_features=1024, out_features=2, bias=False)\n",
            "      )\n",
            "      (tail): ModuleList(\n",
            "        (0): Sequential(\n",
            "          (0): TiedLinear()\n",
            "          (1): Dropout(p=0.2, inplace=False)\n",
            "          (2): TiedLinear()\n",
            "        )\n",
            "        (1): Sequential(\n",
            "          (0): TiedLinear()\n",
            "          (1): Dropout(p=0.2, inplace=False)\n",
            "          (2): TiedLinear()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "2021-12-12 23:39:24 | INFO | fairseq_cli.train | task: LanguageModelingTask\n",
            "2021-12-12 23:39:24 | INFO | fairseq_cli.train | model: TransformerLanguageModel\n",
            "2021-12-12 23:39:24 | INFO | fairseq_cli.train | criterion: AdaptiveLoss\n",
            "2021-12-12 23:39:24 | INFO | fairseq_cli.train | num. shared model params: 246,933,504 (num. trained: 246,933,504)\n",
            "2021-12-12 23:39:24 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)\n",
            "2021-12-12 23:39:24 | INFO | fairseq.data.data_utils | loaded 3,760 examples from: data-bin/wikitext-103/valid\n",
            "2021-12-12 23:39:27 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.embeddings.0.0.weight <- decoder.adaptive_softmax.head.word_proj.weight\n",
            "2021-12-12 23:39:27 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.embeddings.0.1.bias <- decoder.embed_tokens.embeddings.1.1.bias\n",
            "2021-12-12 23:39:27 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.embeddings.0.1.bias <- decoder.embed_tokens.embeddings.2.1.bias\n",
            "2021-12-12 23:39:27 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.embeddings.0.1.bias <- decoder.adaptive_softmax.head.class_proj.bias\n",
            "2021-12-12 23:39:27 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.embeddings.1.0.weight <- decoder.adaptive_softmax.tail.0.2.weight\n",
            "2021-12-12 23:39:27 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.embeddings.1.1.weight <- decoder.adaptive_softmax.tail.0.0.weight\n",
            "2021-12-12 23:39:27 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.embeddings.2.0.weight <- decoder.adaptive_softmax.tail.1.2.weight\n",
            "2021-12-12 23:39:27 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.embeddings.2.1.weight <- decoder.adaptive_softmax.tail.1.0.weight\n",
            "2021-12-12 23:39:27 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2021-12-12 23:39:27 | INFO | fairseq.utils | rank   0: capabilities =  6.0  ; total memory = 15.899 GB ; name = Tesla P100-PCIE-16GB                    \n",
            "2021-12-12 23:39:27 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2021-12-12 23:39:27 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
            "2021-12-12 23:39:27 | INFO | fairseq_cli.train | max tokens per device = 2944 and max sentences per device = None\n",
            "2021-12-12 23:39:27 | INFO | fairseq.trainer | Preparing to load checkpoint /content/drive/MyDrive/checkpoints/transformer_wikitext-103/checkpoint_best.pt\n",
            "2021-12-12 23:39:27 | INFO | fairseq.trainer | No existing checkpoint found /content/drive/MyDrive/checkpoints/transformer_wikitext-103/checkpoint_best.pt\n",
            "2021-12-12 23:39:27 | INFO | fairseq.trainer | loading train data for epoch 1\n",
            "2021-12-12 23:39:29 | INFO | fairseq.data.data_utils | loaded 1,801,350 examples from: data-bin/wikitext-103/train\n",
            "2021-12-12 23:39:29 | INFO | fairseq.trainer | NOTE: your device does NOT support faster training with --fp16 or --amp, please switch to FP32 which is likely to be faster\n",
            "2021-12-12 23:39:29 | INFO | fairseq.data.iterators | grouped total_num_itrs = 11688\n",
            "2021-12-12 23:39:29 | INFO | fairseq.trainer | begin training epoch 1\n",
            "2021-12-12 23:39:29 | INFO | fairseq.quantization_utils | quantizing model (step=0; layers_to_quantize[step]=decoder\\\\.layers\\\\.\\d+\\\\.fc[12])\n",
            "2021-12-12 23:39:29 | INFO | fairseq.quantization_utils | quantized layers: []\n",
            "2021-12-12 23:39:29 | INFO | fairseq.quantization_utils | Non-compressed model size: 941.98 MB. After quantizing 0 layers, size (indexing + centroids + other): 0.00 MB + 0.00 MB + 941.98 MB = 941.98 MB, compression ratio: 1.00x\n",
            "2021-12-12 23:39:29 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2021-12-12 23:39:29 | INFO | fairseq.trainer | NOTE: your device does NOT support faster training with --fp16 or --amp, please switch to FP32 which is likely to be faster\n",
            "2021-12-12 23:39:33 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0\n",
            "2021-12-12 23:39:36 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0\n",
            "2021-12-12 23:39:40 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0\n",
            "2021-12-12 23:44:19 | INFO | train_inner | epoch 001:    103 / 11688 loss=inf, ppl=inf, wps=3181.2, ups=0.36, wpb=8832, bsz=3, num_updates=100, lr=0.05, gnorm=11.721, clip=100, loss_scale=16, train_wall=289, gb_free=2.7, wall=291\n",
            "2021-12-12 23:48:56 | INFO | train_inner | epoch 001:    203 / 11688 loss=inf, ppl=inf, wps=3179.1, ups=0.36, wpb=8832, bsz=3, num_updates=200, lr=0.0499999, gnorm=8.359, clip=100, loss_scale=16, train_wall=277, gb_free=2.7, wall=569\n",
            "2021-12-12 23:53:34 | INFO | train_inner | epoch 001:    303 / 11688 loss=inf, ppl=inf, wps=3179.7, ups=0.36, wpb=8832, bsz=3, num_updates=300, lr=0.0499998, gnorm=6.334, clip=100, loss_scale=16, train_wall=277, gb_free=2.7, wall=847\n",
            "2021-12-12 23:58:12 | INFO | train_inner | epoch 001:    403 / 11688 loss=inf, ppl=inf, wps=3177.4, ups=0.36, wpb=8832, bsz=3, num_updates=400, lr=0.0499997, gnorm=5.45, clip=100, loss_scale=16, train_wall=278, gb_free=2.7, wall=1125\n",
            "2021-12-13 00:02:50 | INFO | train_inner | epoch 001:    503 / 11688 loss=inf, ppl=inf, wps=3178.7, ups=0.36, wpb=8832, bsz=3, num_updates=500, lr=0.0499996, gnorm=5.003, clip=100, loss_scale=16, train_wall=277, gb_free=2.7, wall=1403\n",
            "2021-12-13 00:07:28 | INFO | train_inner | epoch 001:    603 / 11688 loss=inf, ppl=inf, wps=3179.3, ups=0.36, wpb=8832, bsz=3, num_updates=600, lr=0.0499994, gnorm=4.753, clip=100, loss_scale=16, train_wall=277, gb_free=2.7, wall=1681\n",
            "2021-12-13 00:12:05 | INFO | train_inner | epoch 001:    703 / 11688 loss=inf, ppl=inf, wps=3179.4, ups=0.36, wpb=8818, bsz=3, num_updates=700, lr=0.0499992, gnorm=4.536, clip=100, loss_scale=16, train_wall=277, gb_free=2.7, wall=1958\n",
            "2021-12-13 00:16:43 | INFO | train_inner | epoch 001:    803 / 11688 loss=inf, ppl=inf, wps=3179.6, ups=0.36, wpb=8832, bsz=3, num_updates=800, lr=0.0499989, gnorm=4.443, clip=100, loss_scale=16, train_wall=277, gb_free=2.7, wall=2236\n",
            "2021-12-13 00:21:21 | INFO | train_inner | epoch 001:    903 / 11688 loss=inf, ppl=inf, wps=3178, ups=0.36, wpb=8832, bsz=3, num_updates=900, lr=0.0499986, gnorm=4.342, clip=100, loss_scale=16, train_wall=278, gb_free=2.7, wall=2514\n",
            "2021-12-13 00:25:59 | INFO | train_inner | epoch 001:   1003 / 11688 loss=inf, ppl=inf, wps=3178.5, ups=0.36, wpb=8832, bsz=3, num_updates=1000, lr=0.0499983, gnorm=4.183, clip=100, loss_scale=16, train_wall=278, gb_free=2.7, wall=2791\n",
            "2021-12-13 00:30:37 | INFO | train_inner | epoch 001:   1103 / 11688 loss=inf, ppl=inf, wps=3177.5, ups=0.36, wpb=8832, bsz=3, num_updates=1100, lr=0.049998, gnorm=4.051, clip=100, loss_scale=16, train_wall=278, gb_free=2.7, wall=3069\n",
            "2021-12-13 00:35:14 | INFO | train_inner | epoch 001:   1203 / 11688 loss=inf, ppl=inf, wps=3179.3, ups=0.36, wpb=8832, bsz=3, num_updates=1200, lr=0.0499976, gnorm=4.022, clip=100, loss_scale=16, train_wall=277, gb_free=2.7, wall=3347\n",
            "2021-12-13 00:39:52 | INFO | train_inner | epoch 001:   1303 / 11688 loss=9.995, ppl=1020.5, wps=3178.7, ups=0.36, wpb=8832, bsz=3, num_updates=1300, lr=0.0499971, gnorm=3.783, clip=100, loss_scale=16, train_wall=277, gb_free=2.7, wall=3625\n",
            "2021-12-13 00:44:30 | INFO | train_inner | epoch 001:   1403 / 11688 loss=9.948, ppl=987.93, wps=3180.2, ups=0.36, wpb=8832, bsz=3, num_updates=1400, lr=0.0499967, gnorm=3.753, clip=100, loss_scale=16, train_wall=277, gb_free=2.7, wall=3903\n",
            "2021-12-13 00:49:08 | INFO | train_inner | epoch 001:   1503 / 11688 loss=9.868, ppl=934.25, wps=3179, ups=0.36, wpb=8832, bsz=3, num_updates=1500, lr=0.0499962, gnorm=3.672, clip=100, loss_scale=16, train_wall=277, gb_free=2.7, wall=4181\n",
            "2021-12-13 00:53:46 | INFO | train_inner | epoch 001:   1603 / 11688 loss=9.814, ppl=900.42, wps=3178.7, ups=0.36, wpb=8832, bsz=3, num_updates=1600, lr=0.0499957, gnorm=3.624, clip=100, loss_scale=16, train_wall=277, gb_free=2.6, wall=4458\n",
            "2021-12-13 00:58:23 | INFO | train_inner | epoch 001:   1703 / 11688 loss=9.775, ppl=876.35, wps=3179.9, ups=0.36, wpb=8832, bsz=3, num_updates=1700, lr=0.0499951, gnorm=3.552, clip=100, loss_scale=16, train_wall=277, gb_free=2.7, wall=4736\n",
            "2021-12-13 01:03:01 | INFO | train_inner | epoch 001:   1803 / 11688 loss=9.705, ppl=834.63, wps=3179.2, ups=0.36, wpb=8832, bsz=3, num_updates=1800, lr=0.0499945, gnorm=3.502, clip=100, loss_scale=16, train_wall=277, gb_free=2.7, wall=5014\n",
            "2021-12-13 01:07:39 | INFO | train_inner | epoch 001:   1903 / 11688 loss=9.632, ppl=793.53, wps=3180, ups=0.36, wpb=8832, bsz=3, num_updates=1900, lr=0.0499939, gnorm=3.382, clip=100, loss_scale=16, train_wall=277, gb_free=2.7, wall=5292\n",
            "2021-12-13 01:12:17 | INFO | train_inner | epoch 001:   2003 / 11688 loss=9.611, ppl=782.22, wps=3179.4, ups=0.36, wpb=8832, bsz=3, num_updates=2000, lr=0.0499932, gnorm=3.286, clip=100, loss_scale=16, train_wall=277, gb_free=2.7, wall=5570\n",
            "2021-12-13 01:16:54 | INFO | train_inner | epoch 001:   2103 / 11688 loss=9.587, ppl=769.1, wps=3180.6, ups=0.36, wpb=8832, bsz=3, num_updates=2100, lr=0.0499926, gnorm=3.338, clip=100, loss_scale=16, train_wall=277, gb_free=2.7, wall=5847\n",
            "2021-12-13 01:21:32 | INFO | train_inner | epoch 001:   2203 / 11688 loss=9.572, ppl=761.33, wps=3179.3, ups=0.36, wpb=8832, bsz=3, num_updates=2200, lr=0.0499918, gnorm=3.242, clip=100, loss_scale=16, train_wall=277, gb_free=2.7, wall=6125\n",
            "2021-12-13 01:26:10 | INFO | train_inner | epoch 001:   2303 / 11688 loss=9.52, ppl=734.11, wps=3180.6, ups=0.36, wpb=8832, bsz=3, num_updates=2300, lr=0.0499911, gnorm=3.167, clip=100, loss_scale=16, train_wall=277, gb_free=2.7, wall=6403\n",
            "2021-12-13 01:30:48 | INFO | train_inner | epoch 001:   2403 / 11688 loss=9.457, ppl=702.98, wps=3179.9, ups=0.36, wpb=8832, bsz=3, num_updates=2400, lr=0.0499903, gnorm=3.12, clip=100, loss_scale=16, train_wall=277, gb_free=2.7, wall=6680\n",
            "2021-12-13 01:35:25 | INFO | train_inner | epoch 001:   2503 / 11688 loss=9.465, ppl=706.63, wps=3180.4, ups=0.36, wpb=8832, bsz=3, num_updates=2500, lr=0.0499894, gnorm=3.036, clip=100, loss_scale=16, train_wall=277, gb_free=2.7, wall=6958\n",
            "2021-12-13 01:40:03 | INFO | train_inner | epoch 001:   2603 / 11688 loss=9.458, ppl=703.28, wps=3178.4, ups=0.36, wpb=8832, bsz=3, num_updates=2600, lr=0.0499886, gnorm=2.901, clip=100, loss_scale=16, train_wall=278, gb_free=2.7, wall=7236\n",
            "2021-12-13 01:44:41 | INFO | train_inner | epoch 001:   2703 / 11688 loss=9.409, ppl=679.78, wps=3177.7, ups=0.36, wpb=8832, bsz=3, num_updates=2700, lr=0.0499877, gnorm=2.889, clip=100, loss_scale=16, train_wall=278, gb_free=2.7, wall=7514\n",
            "2021-12-13 01:49:19 | INFO | train_inner | epoch 001:   2803 / 11688 loss=9.394, ppl=672.75, wps=3177.7, ups=0.36, wpb=8832, bsz=3, num_updates=2800, lr=0.0499868, gnorm=2.77, clip=100, loss_scale=16, train_wall=278, gb_free=2.7, wall=7792\n",
            "2021-12-13 01:53:57 | INFO | train_inner | epoch 001:   2903 / 11688 loss=9.346, ppl=650.98, wps=3176.6, ups=0.36, wpb=8832, bsz=3, num_updates=2900, lr=0.0499858, gnorm=2.77, clip=100, loss_scale=16, train_wall=278, gb_free=2.7, wall=8070\n",
            "2021-12-13 01:58:35 | INFO | train_inner | epoch 001:   3003 / 11688 loss=9.313, ppl=636.1, wps=3177.9, ups=0.36, wpb=8832, bsz=3, num_updates=3000, lr=0.0499848, gnorm=2.686, clip=100, loss_scale=16, train_wall=278, gb_free=2.7, wall=8348\n",
            "2021-12-13 02:03:13 | INFO | train_inner | epoch 001:   3103 / 11688 loss=9.303, ppl=631.58, wps=3175.8, ups=0.36, wpb=8832, bsz=3, num_updates=3100, lr=0.0499838, gnorm=2.636, clip=100, loss_scale=16, train_wall=278, gb_free=2.7, wall=8626\n",
            "2021-12-13 02:07:51 | INFO | train_inner | epoch 001:   3203 / 11688 loss=9.224, ppl=598.06, wps=3179.2, ups=0.36, wpb=8832, bsz=3, num_updates=3200, lr=0.0499827, gnorm=2.588, clip=100, loss_scale=16, train_wall=277, gb_free=2.7, wall=8904\n",
            "2021-12-13 02:12:29 | INFO | train_inner | epoch 001:   3303 / 11688 loss=9.235, ppl=602.39, wps=3178.2, ups=0.36, wpb=8832, bsz=3, num_updates=3300, lr=0.0499816, gnorm=2.522, clip=100, loss_scale=16, train_wall=278, gb_free=2.7, wall=9182\n",
            "2021-12-13 02:17:07 | INFO | train_inner | epoch 001:   3403 / 11688 loss=9.205, ppl=590.06, wps=3178.7, ups=0.36, wpb=8832, bsz=3, num_updates=3400, lr=0.0499805, gnorm=2.542, clip=100, loss_scale=16, train_wall=277, gb_free=2.7, wall=9460\n",
            "2021-12-13 02:21:45 | INFO | train_inner | epoch 001:   3503 / 11688 loss=9.229, ppl=600.19, wps=3176, ups=0.36, wpb=8832, bsz=3, num_updates=3500, lr=0.0499793, gnorm=2.415, clip=100, loss_scale=16, train_wall=278, gb_free=2.7, wall=9738\n",
            "2021-12-13 02:26:23 | INFO | train_inner | epoch 001:   3603 / 11688 loss=9.153, ppl=569.18, wps=3177.3, ups=0.36, wpb=8832, bsz=3, num_updates=3600, lr=0.0499781, gnorm=2.412, clip=100, loss_scale=16, train_wall=278, gb_free=2.7, wall=10016\n",
            "2021-12-13 02:31:01 | INFO | train_inner | epoch 001:   3703 / 11688 loss=9.163, ppl=573.24, wps=3177.6, ups=0.36, wpb=8832, bsz=3, num_updates=3700, lr=0.0499769, gnorm=2.333, clip=100, loss_scale=16, train_wall=278, gb_free=2.7, wall=10294\n",
            "2021-12-13 02:35:39 | INFO | train_inner | epoch 001:   3803 / 11688 loss=9.128, ppl=559.51, wps=3179.3, ups=0.36, wpb=8832, bsz=3, num_updates=3800, lr=0.0499756, gnorm=2.332, clip=100, loss_scale=16, train_wall=277, gb_free=2.7, wall=10571\n",
            "2021-12-13 02:40:16 | INFO | train_inner | epoch 001:   3903 / 11688 loss=9.09, ppl=545.01, wps=3178.3, ups=0.36, wpb=8832, bsz=3, num_updates=3900, lr=0.0499743, gnorm=2.294, clip=100, loss_scale=16, train_wall=278, gb_free=2.7, wall=10849\n",
            "2021-12-13 02:44:54 | INFO | train_inner | epoch 001:   4003 / 11688 loss=9.088, ppl=544.3, wps=3178.5, ups=0.36, wpb=8832, bsz=3, num_updates=4000, lr=0.049973, gnorm=2.255, clip=100, loss_scale=16, train_wall=278, gb_free=2.7, wall=11127\n",
            "2021-12-13 02:49:32 | INFO | train_inner | epoch 001:   4103 / 11688 loss=9.075, ppl=539.33, wps=3179.8, ups=0.36, wpb=8832, bsz=3, num_updates=4100, lr=0.0499716, gnorm=2.226, clip=100, loss_scale=16, train_wall=277, gb_free=2.7, wall=11405\n",
            "2021-12-13 02:54:10 | INFO | train_inner | epoch 001:   4203 / 11688 loss=9.058, ppl=533.03, wps=3177.5, ups=0.36, wpb=8832, bsz=3, num_updates=4200, lr=0.0499702, gnorm=2.239, clip=100, loss_scale=16, train_wall=278, gb_free=2.7, wall=11683\n",
            "2021-12-13 02:58:48 | INFO | train_inner | epoch 001:   4303 / 11688 loss=9.031, ppl=523.03, wps=3179.1, ups=0.36, wpb=8832, bsz=3, num_updates=4300, lr=0.0499688, gnorm=2.152, clip=100, loss_scale=16, train_wall=277, gb_free=2.7, wall=11961\n",
            "2021-12-13 03:03:26 | INFO | train_inner | epoch 001:   4403 / 11688 loss=9.028, ppl=521.89, wps=3177.8, ups=0.36, wpb=8832, bsz=3, num_updates=4400, lr=0.0499673, gnorm=2.176, clip=100, loss_scale=16, train_wall=278, gb_free=2.7, wall=12239\n",
            "2021-12-13 03:08:03 | INFO | fairseq.quantization_utils | quantizing model (step=1; layers_to_quantize[step]=decoder\\\\.embed_tokens\\\\.embeddings\\\\.[012]\\\\.[01])\n",
            "2021-12-13 03:08:03 | INFO | fairseq.quantization_utils | quantized layers: []\n",
            "2021-12-13 03:08:03 | INFO | fairseq.quantization_utils | Non-compressed model size: 941.98 MB. After quantizing 0 layers, size (indexing + centroids + other): 0.00 MB + 0.00 MB + 941.98 MB = 941.98 MB, compression ratio: 1.00x\n",
            "2021-12-13 03:08:03 | INFO | fairseq.trainer | NOTE: your device does NOT support faster training with --fp16 or --amp, please switch to FP32 which is likely to be faster\n",
            "2021-12-13 03:08:03 | INFO | train_inner | epoch 001:   4503 / 11688 loss=8.96, ppl=497.94, wps=3179.6, ups=0.36, wpb=8832, bsz=3, num_updates=4500, lr=0.0499658, gnorm=2.125, clip=100, loss_scale=128, train_wall=277, gb_free=2.7, wall=12516\n",
            "2021-12-13 03:10:25 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0\n",
            "2021-12-13 03:12:44 | INFO | train_inner | epoch 001:   4604 / 11688 loss=8.94, ppl=491.27, wps=3148.5, ups=0.36, wpb=8832, bsz=3, num_updates=4600, lr=0.0499643, gnorm=2.057, clip=100, loss_scale=64, train_wall=280, gb_free=2.7, wall=12797\n",
            "2021-12-13 03:17:22 | INFO | train_inner | epoch 001:   4704 / 11688 loss=8.934, ppl=489.16, wps=3178.2, ups=0.36, wpb=8832, bsz=3, num_updates=4700, lr=0.0499627, gnorm=2.101, clip=100, loss_scale=64, train_wall=278, gb_free=2.7, wall=13075\n",
            "2021-12-13 03:22:00 | INFO | train_inner | epoch 001:   4804 / 11688 loss=8.985, ppl=506.76, wps=3178, ups=0.36, wpb=8832, bsz=3, num_updates=4800, lr=0.0499611, gnorm=2.063, clip=100, loss_scale=64, train_wall=278, gb_free=2.7, wall=13353\n",
            "2021-12-13 03:26:38 | INFO | train_inner | epoch 001:   4904 / 11688 loss=8.98, ppl=504.82, wps=3177.6, ups=0.36, wpb=8832, bsz=3, num_updates=4900, lr=0.0499595, gnorm=2.077, clip=100, loss_scale=64, train_wall=278, gb_free=2.7, wall=13631\n",
            "2021-12-13 03:31:16 | INFO | train_inner | epoch 001:   5004 / 11688 loss=8.933, ppl=488.91, wps=3179.6, ups=0.36, wpb=8832, bsz=3, num_updates=5000, lr=0.0499578, gnorm=2.043, clip=100, loss_scale=64, train_wall=277, gb_free=2.7, wall=13908\n",
            "2021-12-13 03:35:53 | INFO | train_inner | epoch 001:   5104 / 11688 loss=8.858, ppl=463.92, wps=3179.2, ups=0.36, wpb=8832, bsz=3, num_updates=5100, lr=0.0499561, gnorm=2.035, clip=100, loss_scale=64, train_wall=277, gb_free=2.7, wall=14186\n",
            "2021-12-13 03:40:31 | INFO | train_inner | epoch 001:   5204 / 11688 loss=8.899, ppl=477.53, wps=3178.6, ups=0.36, wpb=8832, bsz=3, num_updates=5200, lr=0.0499543, gnorm=1.974, clip=100, loss_scale=64, train_wall=278, gb_free=2.7, wall=14464\n",
            "2021-12-13 03:45:09 | INFO | train_inner | epoch 001:   5304 / 11688 loss=8.852, ppl=462.22, wps=3178.1, ups=0.36, wpb=8832, bsz=3, num_updates=5300, lr=0.0499526, gnorm=1.937, clip=100, loss_scale=64, train_wall=278, gb_free=2.7, wall=14742\n",
            "2021-12-13 03:49:47 | INFO | train_inner | epoch 001:   5404 / 11688 loss=8.795, ppl=444.18, wps=3178.2, ups=0.36, wpb=8832, bsz=3, num_updates=5400, lr=0.0499508, gnorm=1.955, clip=100, loss_scale=64, train_wall=278, gb_free=2.7, wall=15020\n",
            "2021-12-13 03:54:25 | INFO | train_inner | epoch 001:   5504 / 11688 loss=8.854, ppl=462.88, wps=3176, ups=0.36, wpb=8832, bsz=3, num_updates=5500, lr=0.0499489, gnorm=1.945, clip=100, loss_scale=64, train_wall=278, gb_free=2.7, wall=15298\n",
            "2021-12-13 03:59:03 | INFO | train_inner | epoch 001:   5604 / 11688 loss=8.842, ppl=458.74, wps=3179.2, ups=0.36, wpb=8832, bsz=3, num_updates=5600, lr=0.0499471, gnorm=1.923, clip=100, loss_scale=64, train_wall=277, gb_free=2.7, wall=15576\n",
            "2021-12-13 04:03:41 | INFO | train_inner | epoch 001:   5704 / 11688 loss=8.799, ppl=445.39, wps=3178.6, ups=0.36, wpb=8832, bsz=3, num_updates=5700, lr=0.0499451, gnorm=1.888, clip=100, loss_scale=64, train_wall=278, gb_free=2.7, wall=15854\n",
            "2021-12-13 04:08:19 | INFO | train_inner | epoch 001:   5804 / 11688 loss=8.81, ppl=448.78, wps=3178.3, ups=0.36, wpb=8832, bsz=3, num_updates=5800, lr=0.0499432, gnorm=1.862, clip=100, loss_scale=64, train_wall=278, gb_free=2.7, wall=16131\n",
            "2021-12-13 04:12:57 | INFO | train_inner | epoch 001:   5904 / 11688 loss=8.757, ppl=432.74, wps=3178.1, ups=0.36, wpb=8832, bsz=3, num_updates=5900, lr=0.0499412, gnorm=1.861, clip=100, loss_scale=64, train_wall=278, gb_free=2.7, wall=16409\n",
            "2021-12-13 04:17:34 | INFO | train_inner | epoch 001:   6004 / 11688 loss=8.773, ppl=437.41, wps=3178.7, ups=0.36, wpb=8832, bsz=3, num_updates=6000, lr=0.0499392, gnorm=1.831, clip=100, loss_scale=64, train_wall=277, gb_free=2.7, wall=16687\n",
            "2021-12-13 04:21:06 | INFO | fairseq.trainer | NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0\n",
            "2021-12-13 04:22:15 | INFO | train_inner | epoch 001:   6105 / 11688 loss=8.801, ppl=446.16, wps=3146.8, ups=0.36, wpb=8832, bsz=3, num_updates=6100, lr=0.0499372, gnorm=1.833, clip=100, loss_scale=32, train_wall=280, gb_free=2.7, wall=16968\n",
            "2021-12-13 04:26:53 | INFO | train_inner | epoch 001:   6205 / 11688 loss=8.803, ppl=446.6, wps=3176.9, ups=0.36, wpb=8832, bsz=3, num_updates=6200, lr=0.0499351, gnorm=1.844, clip=100, loss_scale=32, train_wall=278, gb_free=2.7, wall=17246\n",
            "2021-12-13 04:31:31 | INFO | train_inner | epoch 001:   6305 / 11688 loss=8.697, ppl=414.95, wps=3179.1, ups=0.36, wpb=8832, bsz=3, num_updates=6300, lr=0.049933, gnorm=1.786, clip=100, loss_scale=32, train_wall=277, gb_free=2.7, wall=17524\n",
            "2021-12-13 04:36:09 | INFO | train_inner | epoch 001:   6405 / 11688 loss=8.71, ppl=418.89, wps=3178.1, ups=0.36, wpb=8832, bsz=3, num_updates=6400, lr=0.0499309, gnorm=1.775, clip=100, loss_scale=32, train_wall=278, gb_free=2.7, wall=17802\n",
            "2021-12-13 04:40:47 | INFO | train_inner | epoch 001:   6505 / 11688 loss=8.685, ppl=411.67, wps=3178.1, ups=0.36, wpb=8832, bsz=3, num_updates=6500, lr=0.0499287, gnorm=1.783, clip=100, loss_scale=32, train_wall=278, gb_free=2.7, wall=18079\n",
            "2021-12-13 04:45:25 | INFO | train_inner | epoch 001:   6605 / 11688 loss=8.671, ppl=407.68, wps=3178.1, ups=0.36, wpb=8832, bsz=3, num_updates=6600, lr=0.0499265, gnorm=1.793, clip=100, loss_scale=32, train_wall=278, gb_free=2.7, wall=18357\n",
            "2021-12-13 04:50:02 | INFO | train_inner | epoch 001:   6705 / 11688 loss=8.669, ppl=407, wps=3180, ups=0.36, wpb=8832, bsz=3, num_updates=6700, lr=0.0499242, gnorm=1.759, clip=100, loss_scale=32, train_wall=277, gb_free=2.7, wall=18635\n",
            "2021-12-13 04:54:40 | INFO | train_inner | epoch 001:   6805 / 11688 loss=8.662, ppl=405.03, wps=3177.6, ups=0.36, wpb=8832, bsz=3, num_updates=6800, lr=0.0499219, gnorm=1.743, clip=100, loss_scale=32, train_wall=278, gb_free=2.7, wall=18913\n",
            "2021-12-13 04:59:18 | INFO | train_inner | epoch 001:   6905 / 11688 loss=8.658, ppl=403.81, wps=3179.8, ups=0.36, wpb=8832, bsz=3, num_updates=6900, lr=0.0499196, gnorm=1.783, clip=100, loss_scale=32, train_wall=277, gb_free=2.7, wall=19191\n",
            "2021-12-13 05:03:56 | INFO | train_inner | epoch 001:   7005 / 11688 loss=8.59, ppl=385.43, wps=3178.2, ups=0.36, wpb=8832, bsz=3, num_updates=7000, lr=0.0499173, gnorm=1.726, clip=100, loss_scale=32, train_wall=278, gb_free=2.7, wall=19469\n",
            "2021-12-13 05:08:34 | INFO | train_inner | epoch 001:   7105 / 11688 loss=8.609, ppl=390.33, wps=3179, ups=0.36, wpb=8832, bsz=3, num_updates=7100, lr=0.0499149, gnorm=1.727, clip=100, loss_scale=32, train_wall=277, gb_free=2.7, wall=19747\n",
            "2021-12-13 05:13:12 | INFO | train_inner | epoch 001:   7205 / 11688 loss=8.612, ppl=391.14, wps=3177.9, ups=0.36, wpb=8832, bsz=3, num_updates=7200, lr=0.0499125, gnorm=1.698, clip=100, loss_scale=32, train_wall=278, gb_free=2.7, wall=20024\n",
            "2021-12-13 05:17:50 | INFO | train_inner | epoch 001:   7305 / 11688 loss=8.555, ppl=376.11, wps=3178.3, ups=0.36, wpb=8832, bsz=3, num_updates=7300, lr=0.0499101, gnorm=1.709, clip=100, loss_scale=32, train_wall=278, gb_free=2.7, wall=20302\n",
            "2021-12-13 05:22:27 | INFO | train_inner | epoch 001:   7405 / 11688 loss=8.573, ppl=380.71, wps=3178.8, ups=0.36, wpb=8832, bsz=3, num_updates=7400, lr=0.0499076, gnorm=1.675, clip=100, loss_scale=32, train_wall=277, gb_free=2.7, wall=20580\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate quantized model"
      ],
      "metadata": {
        "id": "cgaRUCQ5CxVv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd fairseq\n",
        "\n",
        "!fairseq-eval-lm data-bin/wikitext-103 --path checkpoints/tansformer_wikitext-103-quantized/ \\\n",
        "    --sample-break-mode complete \\\n",
        "    --max-tokens 3072 \\\n",
        "    --context-window 2560 \\\n",
        "    --softmax-batch 1024 \\\n",
        "    --gen-subset valid\n",
        "\n",
        "%cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "df1DG2UvC2C-",
        "outputId": "45f323e1-3488-494a-9fc7-ae7962e80599"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/fairseq\n",
            "2021-12-11 06:21:44 | INFO | fairseq_cli.eval_lm | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': 'checkpoints/tansformer_wikitext-103-quantized/', 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 3072, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 3072, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'valid', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 2560, 'softmax_batch': 1024}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': None, 'task': {'_name': 'language_modeling', 'data': 'data-bin/wikitext-103', 'sample_break_mode': 'complete', 'tokens_per_sample': 1024, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 1, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
            "2021-12-11 06:21:44 | INFO | fairseq.tasks.language_modeling | dictionary: 267744 types\n",
            "2021-12-11 06:21:44 | INFO | fairseq_cli.eval_lm | loading model(s) from checkpoints/tansformer_wikitext-103-quantized/\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/fairseq-eval-lm\", line 33, in <module>\n",
            "    sys.exit(load_entry_point('fairseq', 'console_scripts', 'fairseq-eval-lm')())\n",
            "  File \"/content/fairseq/fairseq_cli/eval_lm.py\", line 343, in cli_main\n",
            "    distributed_utils.call_main(convert_namespace_to_omegaconf(args), main)\n",
            "  File \"/content/fairseq/fairseq/distributed/utils.py\", line 369, in call_main\n",
            "    main(cfg, **kwargs)\n",
            "  File \"/content/fairseq/fairseq_cli/eval_lm.py\", line 259, in main\n",
            "    task=task,\n",
            "  File \"/content/fairseq/fairseq/checkpoint_utils.py\", line 418, in load_model_ensemble_and_task\n",
            "    raise IOError(\"Model file not found: {}\".format(filename))\n",
            "OSError: Model file not found: checkpoints/tansformer_wikitext-103-quantized/\n",
            "/content\n"
          ]
        }
      ]
    }
  ]
}