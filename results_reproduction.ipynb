{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "results-reproduction.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "O04oFcDQekud",
        "eZXxaCaPSt54"
      ],
      "mount_file_id": "1CfQhsbf3C2BokXiO9I4HPzH5mYzOVH8Z",
      "authorship_tag": "ABX9TyNQ3SwhQ1j3be1xgPtAf/tt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/felixsimard/comp551-p4/blob/main/results_reproduction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf apex\n",
        "!rm -rf fairseq"
      ],
      "metadata": {
        "id": "5fwy5a3UVWLw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install required dependencies"
      ],
      "metadata": {
        "id": "O04oFcDQekud"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorboardX"
      ],
      "metadata": {
        "id": "6tStByDn0T3U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/pytorch/fairseq\n",
        "%cd fairseq\n",
        "!pip install --editable ./\n",
        "%cd .."
      ],
      "metadata": {
        "id": "SRqzvcR3Tzwm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/NVIDIA/apex\n",
        "%cd apex\n",
        "!pip install -v --disable-pip-version-check --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./\n",
        "%cd .."
      ],
      "metadata": {
        "id": "B7wf847nUNn4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Finetune RoBERTa (does not work)"
      ],
      "metadata": {
        "id": "eZXxaCaPSt54"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd fairseq\n",
        "!./examples/roberta/preprocess_GLUE_tasks.sh /content/drive/MyDrive/glue_data RTE\n",
        "%cd .."
      ],
      "metadata": {
        "id": "PBo3v5kEyKdr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, torchvision.models\n",
        "model = torch.hub.load('pytorch/fairseq', 'roberta.large')\n",
        "path = '/content/drive/MyDrive/roberta.large/model2.pt'\n",
        "torch.save(model.state_dict(), path) # nothing else here\n",
        "# model.load_state_dict(torch.load(path))"
      ],
      "metadata": {
        "id": "f1Y79vIvgtR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd fairseq\n",
        "\n",
        "!TOTAL_NUM_UPDATES=2036\n",
        "!WARMUP_UPDATES=122\n",
        "!LR=2e-05\n",
        "!NUM_CLASSES=2\n",
        "!MAX_SENTENCES=16\n",
        "!ROBERTA_PATH=/content/drive/MyDrive/roberta.large/dict.pth\n",
        "\n",
        "!fairseq-train /content/fairseq/RTE-bin \\\n",
        "    --restore-file /content/drive/MyDrive/roberta.large/model.pt \\\n",
        "    --max-positions 512 \\\n",
        "    --batch-size 16 \\\n",
        "    --max-tokens 4400 \\\n",
        "    --task sentence_prediction \\\n",
        "    --reset-optimizer --reset-dataloader --reset-meters \\\n",
        "    --required-batch-size-multiple 1 \\\n",
        "    --init-token 0 --separator-token 2 \\\n",
        "    --arch roberta_large \\\n",
        "    --criterion sentence_prediction \\\n",
        "    --num-classes 2 \\\n",
        "    --dropout 0.1 --attention-dropout 0.1 \\\n",
        "    --weight-decay 0.1 --optimizer adam --adam-betas \"(0.9, 0.98)\" --adam-eps 1e-06 \\\n",
        "    --clip-norm 0.0 \\\n",
        "    --lr-scheduler polynomial_decay --lr 2e-05 --total-num-update 2036 --warmup-updates 122 \\\n",
        "    --fp16 --fp16-init-scale 4 --threshold-loss-scale 1 --fp16-scale-window 128 \\\n",
        "    --max-epoch 10 \\\n",
        "    --find-unused-parameters \\\n",
        "    --best-checkpoint-metric accuracy --maximize-best-checkpoint-metric \\\n",
        "    --ddp-backend legacy_ddp \\\n",
        "    --quant-noise-pq 0.2 --quant-noise-pq-block-size 8\n",
        "\n",
        "%cd ..\n"
      ],
      "metadata": {
        "id": "NH3slDCy3-is"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!CUDA_VISIBLE_DEVICES=0 fairseq-hydra-train --config-dir /content/fairseq/examples/roberta/config/finetuning --config-name mnli \\\n",
        "task.data=/content/fairseq/MNLI-bin checkpoint.restore_file=$ROBERTA_PATH "
      ],
      "metadata": {
        "id": "3Em1ylWkNQ8V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# WikiText Language Model"
      ],
      "metadata": {
        "id": "vvOMHIoK43QM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download the data"
      ],
      "metadata": {
        "id": "9phZ7Tjt5Yut"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd fairseq\n",
        "\n",
        "%cd examples/language_model/\n",
        "!bash prepare-wikitext-103.sh\n",
        "%cd ../..\n",
        "\n",
        "%cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MxONDIv_418h",
        "outputId": "e0d7bd38-65fa-438e-de3f-0bdf7d9b4c13"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/fairseq\n",
            "/content/fairseq/examples/language_model\n",
            "--2021-12-13 18:07:41--  https://s3.amazonaws.com/research.metamind.io/wikitext/wikitext-103-v1.zip\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.76.166\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.76.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 190229076 (181M) [application/zip]\n",
            "Saving to: ‘wikitext-103-v1.zip’\n",
            "\n",
            "wikitext-103-v1.zip 100%[===================>] 181.42M  45.2MB/s    in 4.4s    \n",
            "\n",
            "2021-12-13 18:07:46 (40.8 MB/s) - ‘wikitext-103-v1.zip’ saved [190229076/190229076]\n",
            "\n",
            "https://s3.amazonaws.com/research.metamind.io/wikitext/wikitext-103-v1.zip successfully downloaded.\n",
            "Archive:  wikitext-103-v1.zip\n",
            "   creating: wikitext-103/\n",
            "  inflating: wikitext-103/wiki.test.tokens  \n",
            "  inflating: wikitext-103/wiki.valid.tokens  \n",
            "  inflating: wikitext-103/wiki.train.tokens  \n",
            "/content/fairseq\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocess the data"
      ],
      "metadata": {
        "id": "KniHy6KI6s4X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd fairseq\n",
        "\n",
        "!TEXT=examples/language_model/wikitext-103; \\\n",
        " fairseq-preprocess \\\n",
        "    --only-source \\\n",
        "    --trainpref $TEXT/wiki.train.tokens \\\n",
        "    --validpref $TEXT/wiki.valid.tokens \\\n",
        "    --testpref $TEXT/wiki.test.tokens \\\n",
        "    --destdir data-bin/wikitext-103 \\\n",
        "    --workers 20\n",
        "\n",
        "%cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxNYTg4t5jMT",
        "outputId": "4e6cb6c0-6a9e-44d2-b0b8-6999ed17629a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/fairseq\n",
            "2021-12-13 18:07:54 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, amp=False, amp_batch_retries=2, amp_init_scale=128, amp_scale_window=None, azureml_logging=False, bf16=False, bpe=None, cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='data-bin/wikitext-103', dict_only=False, empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_file=None, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, on_cpu_convert_precision=False, only_source=True, optimizer=None, padding_factor=8, plasma_path='/tmp/plasma', profile=False, quantization_config_path=None, reset_logging=False, scoring='bleu', seed=1, source_lang=None, srcdict=None, suppress_crashes=False, target_lang=None, task='translation', tensorboard_logdir=None, testpref='examples/language_model/wikitext-103/wiki.test.tokens', tgtdict=None, threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref='examples/language_model/wikitext-103/wiki.train.tokens', use_plasma_view=False, user_dir=None, validpref='examples/language_model/wikitext-103/wiki.valid.tokens', wandb_project=None, workers=20)\n",
            "2021-12-13 18:10:57 | INFO | fairseq_cli.preprocess | [None] Dictionary: 267744 types\n",
            "2021-12-13 18:18:05 | INFO | fairseq_cli.preprocess | [None] examples/language_model/wikitext-103/wiki.train.tokens: 1801350 sents, 103227021 tokens, 0.0% replaced by <unk>\n",
            "2021-12-13 18:18:05 | INFO | fairseq_cli.preprocess | [None] Dictionary: 267744 types\n",
            "2021-12-13 18:18:10 | INFO | fairseq_cli.preprocess | [None] examples/language_model/wikitext-103/wiki.valid.tokens: 3760 sents, 217646 tokens, 0.0% replaced by <unk>\n",
            "2021-12-13 18:18:10 | INFO | fairseq_cli.preprocess | [None] Dictionary: 267744 types\n",
            "2021-12-13 18:18:15 | INFO | fairseq_cli.preprocess | [None] examples/language_model/wikitext-103/wiki.test.tokens: 4358 sents, 245569 tokens, 0.0% replaced by <unk>\n",
            "2021-12-13 18:18:15 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to data-bin/wikitext-103\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the language model without noise"
      ],
      "metadata": {
        "id": "xigVItXP7yNw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd fairseq\n",
        "\n",
        "!fairseq-train --task language_modeling data-bin/wikitext-103  \\\n",
        "    --save-dir /content/drive/MyDrive/checkpoints/transformer_wikitext-103-nonoise \\\n",
        "    --adaptive-input --adaptive-input-cutoff 20000,60000 --adaptive-input-factor 4 \\\n",
        "    --adaptive-softmax-cutoff 20000,60000 --adaptive-softmax-dropout 0.2 --adaptive-softmax-factor 4.0 \\\n",
        "    --tie-adaptive-proj --tie-adaptive-weights \\\n",
        "    --arch transformer_lm_gbw \\\n",
        "    --attention-dropout 0.1 --dropout 0.2 --relu-dropout 0.1 \\\n",
        "    --clip-norm 0.1 --criterion adaptive_loss \\\n",
        "    --ddp-backend legacy_ddp \\\n",
        "    --decoder-attention-heads 8 --decoder-embed-dim 1024 --decoder-ffn-embed-dim 4096 --decoder-input-dim 1024 \\\n",
        "    --decoder-layers 16 --decoder-normalize-before --decoder-output-dim 1024 \\\n",
        "    --min-lr 0.0001 --lr-period-updates 270000 --lr-scheduler cosine --lr-shrink 0.75 --lr 1.0 --t-mult 2.0 \\\n",
        "    --max-tokens 3072 --tokens-per-sample 1024 --momentum 0.99 --optimizer nag \\\n",
        "    --sample-break-mode none --update-freq 3 \\\n",
        "    --warmup-init-lr 1e-07 --warmup-updates 16000 \\\n",
        "    --weight-decay 0 --seed 1 --stop-min-lr 1e-09 \n",
        "\n",
        "%cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-eFRMXXS7x2v",
        "outputId": "ffcc9434-0742-4e17-f83e-f735d57ba211"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/fairseq\n",
            "2021-12-13 18:18:20 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 3072, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 3072, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.1, 'sentence_avg': False, 'update_freq': [3], 'lr': [1.0], 'stop_min_lr': 1e-09, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/content/drive/MyDrive/checkpoints/transformer_wikitext-103-nonoise', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'transformer_lm_gbw', 'activation_fn': 'relu', 'dropout': 0.2, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'relu_dropout': 0.1, 'decoder_embed_dim': 1024, 'decoder_output_dim': 1024, 'decoder_input_dim': 1024, 'decoder_ffn_embed_dim': 4096, 'decoder_layers': 16, 'decoder_attention_heads': 8, 'decoder_normalize_before': True, 'no_decoder_final_norm': True, 'adaptive_softmax_cutoff': '20000,60000', 'adaptive_softmax_dropout': 0.2, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': False, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': True, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': '20000,60000', 'tie_adaptive_weights': True, 'tie_adaptive_proj': True, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': False, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 0, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 1024, 'max_target_positions': None, 'tpu': False}, 'task': {'_name': 'language_modeling', 'data': 'data-bin/wikitext-103', 'sample_break_mode': 'none', 'tokens_per_sample': 1024, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 1, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'criterion': {'_name': 'adaptive_loss', 'sentence_avg': False, 'ddp_backend': 'legacy_ddp'}, 'optimizer': {'_name': 'nag', 'momentum': 0.99, 'weight_decay': 0.0, 'lr': [1.0]}, 'lr_scheduler': {'_name': 'cosine', 'warmup_updates': 16000, 'warmup_init_lr': 1e-07, 'lr': [1.0], 'min_lr': 0.0001, 't_mult': 2.0, 'lr_period_updates': 270000.0, 'lr_shrink': 0.75, 'max_update': 0}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
            "2021-12-13 18:18:20 | INFO | fairseq.tasks.language_modeling | dictionary: 267744 types\n",
            "2021-12-13 18:18:23 | INFO | fairseq_cli.train | TransformerLanguageModel(\n",
            "  (decoder): TransformerDecoder(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_tokens): AdaptiveInput(\n",
            "      (embeddings): ModuleList(\n",
            "        (0): Sequential(\n",
            "          (0): Embedding(20000, 1024, padding_idx=1)\n",
            "          (1): Linear(in_features=1024, out_features=1024, bias=False)\n",
            "        )\n",
            "        (1): Sequential(\n",
            "          (0): Embedding(40000, 256)\n",
            "          (1): Linear(in_features=256, out_features=1024, bias=False)\n",
            "        )\n",
            "        (2): Sequential(\n",
            "          (0): Embedding(207744, 64)\n",
            "          (1): Linear(in_features=64, out_features=1024, bias=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (layers): ModuleList(\n",
            "      (0): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (1): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (2): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (3): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (4): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (5): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (6): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (7): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (8): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (9): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (10): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (11): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (12): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (13): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (14): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (15): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (adaptive_softmax): AdaptiveSoftmax(\n",
            "      (dropout_module): FairseqDropout()\n",
            "      (lsm): LogSoftmax(dim=1)\n",
            "      (head): TiedHeadModule(\n",
            "        (word_proj): TiedLinear()\n",
            "        (class_proj): Linear(in_features=1024, out_features=2, bias=False)\n",
            "      )\n",
            "      (tail): ModuleList(\n",
            "        (0): Sequential(\n",
            "          (0): TiedLinear()\n",
            "          (1): Dropout(p=0.2, inplace=False)\n",
            "          (2): TiedLinear()\n",
            "        )\n",
            "        (1): Sequential(\n",
            "          (0): TiedLinear()\n",
            "          (1): Dropout(p=0.2, inplace=False)\n",
            "          (2): TiedLinear()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "2021-12-13 18:18:23 | INFO | fairseq_cli.train | task: LanguageModelingTask\n",
            "2021-12-13 18:18:23 | INFO | fairseq_cli.train | model: TransformerLanguageModel\n",
            "2021-12-13 18:18:23 | INFO | fairseq_cli.train | criterion: AdaptiveLoss\n",
            "2021-12-13 18:18:23 | INFO | fairseq_cli.train | num. shared model params: 246,933,504 (num. trained: 246,933,504)\n",
            "2021-12-13 18:18:23 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)\n",
            "2021-12-13 18:18:23 | INFO | fairseq.data.data_utils | loaded 3,760 examples from: data-bin/wikitext-103/valid\n",
            "2021-12-13 18:18:32 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.embeddings.0.0.weight <- decoder.adaptive_softmax.head.word_proj.weight\n",
            "2021-12-13 18:18:32 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.embeddings.0.1.bias <- decoder.embed_tokens.embeddings.1.1.bias\n",
            "2021-12-13 18:18:32 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.embeddings.0.1.bias <- decoder.embed_tokens.embeddings.2.1.bias\n",
            "2021-12-13 18:18:32 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.embeddings.0.1.bias <- decoder.adaptive_softmax.head.class_proj.bias\n",
            "2021-12-13 18:18:32 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.embeddings.1.0.weight <- decoder.adaptive_softmax.tail.0.2.weight\n",
            "2021-12-13 18:18:32 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.embeddings.1.1.weight <- decoder.adaptive_softmax.tail.0.0.weight\n",
            "2021-12-13 18:18:32 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.embeddings.2.0.weight <- decoder.adaptive_softmax.tail.1.2.weight\n",
            "2021-12-13 18:18:32 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.embeddings.2.1.weight <- decoder.adaptive_softmax.tail.1.0.weight\n",
            "2021-12-13 18:18:32 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2021-12-13 18:18:32 | INFO | fairseq.utils | rank   0: capabilities =  6.0  ; total memory = 15.899 GB ; name = Tesla P100-PCIE-16GB                    \n",
            "2021-12-13 18:18:32 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2021-12-13 18:18:32 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
            "2021-12-13 18:18:32 | INFO | fairseq_cli.train | max tokens per device = 3072 and max sentences per device = None\n",
            "2021-12-13 18:18:32 | INFO | fairseq.trainer | Preparing to load checkpoint /content/drive/MyDrive/checkpoints/transformer_wikitext-103-nonoise/checkpoint_last.pt\n",
            "2021-12-13 18:18:32 | INFO | fairseq.trainer | No existing checkpoint found /content/drive/MyDrive/checkpoints/transformer_wikitext-103-nonoise/checkpoint_last.pt\n",
            "2021-12-13 18:18:32 | INFO | fairseq.trainer | loading train data for epoch 1\n",
            "2021-12-13 18:18:33 | INFO | fairseq.data.data_utils | loaded 1,801,350 examples from: data-bin/wikitext-103/train\n",
            "2021-12-13 18:18:33 | INFO | fairseq.data.iterators | grouped total_num_itrs = 11201\n",
            "epoch 001:   0% 0/11201 [00:00<?, ?it/s]2021-12-13 18:18:33 | INFO | fairseq.trainer | begin training epoch 1\n",
            "2021-12-13 18:18:33 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 001:  54% 6097/11201 [3:53:16<3:15:11,  2.29s/it, loss=7.697, ppl=207.46, wps=4020.2, ups=0.44, wpb=9216, bsz=9, num_updates=6000, lr=0.375, gnorm=1.194, clip=100, train_wall=229, gb_free=4, wall=13774]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model with noise"
      ],
      "metadata": {
        "id": "6tbB_vZ26wrj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd fairseq\n",
        "\n",
        "!fairseq-train --task language_modeling data-bin/wikitext-103  \\\n",
        "    --save-dir /content/drive/MyDrive/checkpoints/transformer_wikitext-103 \\\n",
        "    --adaptive-input --adaptive-input-cutoff 20000,60000 --adaptive-input-factor 4 \\\n",
        "    --adaptive-softmax-cutoff 20000,60000 --adaptive-softmax-dropout 0.2 --adaptive-softmax-factor 4.0 \\\n",
        "    --tie-adaptive-proj --tie-adaptive-weights \\\n",
        "    --arch transformer_lm_gbw \\\n",
        "    --attention-dropout 0.1 --dropout 0.2 --relu-dropout 0.1 \\\n",
        "    --clip-norm 0.1 --criterion adaptive_loss \\\n",
        "    --ddp-backend legacy_ddp \\\n",
        "    --decoder-attention-heads 8 --decoder-embed-dim 1024 --decoder-ffn-embed-dim 4096 --decoder-input-dim 1024 \\\n",
        "    --decoder-layers 16 --decoder-normalize-before --decoder-output-dim 1024 \\\n",
        "    --min-lr 0.0001 --lr-period-updates 270000 --lr-scheduler cosine --lr-shrink 0.75 --lr 1.0 --t-mult 2.0 \\\n",
        "    --max-tokens 3072 --tokens-per-sample 1024 --momentum 0.99 --optimizer nag \\\n",
        "    --sample-break-mode none --update-freq 3 \\\n",
        "    --warmup-init-lr 1e-07 --warmup-updates 16000 \\\n",
        "    --weight-decay 0 --seed 1 --stop-min-lr 1e-09 \\\n",
        "    --quant-noise-pq 0.05 --quant-noise-pq-block-size 8\n",
        "\n",
        "%cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xUNzP_Y97iK3",
        "outputId": "e4e6df1c-496c-40b9-be99-0745635cc5ae"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/fairseq\n",
            "2021-12-12 06:09:55 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 3072, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 3072, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.1, 'sentence_avg': False, 'update_freq': [3], 'lr': [1.0], 'stop_min_lr': 1e-09, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/content/drive/MyDrive/checkpoints/transformer_wikitext-103', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'transformer_lm_gbw', 'activation_fn': 'relu', 'dropout': 0.2, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'relu_dropout': 0.1, 'decoder_embed_dim': 1024, 'decoder_output_dim': 1024, 'decoder_input_dim': 1024, 'decoder_ffn_embed_dim': 4096, 'decoder_layers': 16, 'decoder_attention_heads': 8, 'decoder_normalize_before': True, 'no_decoder_final_norm': True, 'adaptive_softmax_cutoff': '20000,60000', 'adaptive_softmax_dropout': 0.2, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': False, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': True, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': '20000,60000', 'tie_adaptive_weights': True, 'tie_adaptive_proj': True, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': False, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.05, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 0, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 1024, 'max_target_positions': None, 'tpu': False}, 'task': {'_name': 'language_modeling', 'data': 'data-bin/wikitext-103', 'sample_break_mode': 'none', 'tokens_per_sample': 1024, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 1, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'criterion': {'_name': 'adaptive_loss', 'sentence_avg': False, 'ddp_backend': 'legacy_ddp'}, 'optimizer': {'_name': 'nag', 'momentum': 0.99, 'weight_decay': 0.0, 'lr': [1.0]}, 'lr_scheduler': {'_name': 'cosine', 'warmup_updates': 16000, 'warmup_init_lr': 1e-07, 'lr': [1.0], 'min_lr': 0.0001, 't_mult': 2.0, 'lr_period_updates': 270000.0, 'lr_shrink': 0.75, 'max_update': 0}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
            "2021-12-12 06:09:55 | INFO | fairseq.tasks.language_modeling | dictionary: 267744 types\n",
            "2021-12-12 06:09:58 | INFO | fairseq_cli.train | TransformerLanguageModel(\n",
            "  (decoder): TransformerDecoder(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_tokens): AdaptiveInput(\n",
            "      (embeddings): ModuleList(\n",
            "        (0): Sequential(\n",
            "          (0): Embedding(20000, 1024, padding_idx=1)\n",
            "          (1): Linear(in_features=1024, out_features=1024, bias=False)\n",
            "        )\n",
            "        (1): Sequential(\n",
            "          (0): Embedding(40000, 256)\n",
            "          (1): Linear(in_features=256, out_features=1024, bias=False)\n",
            "        )\n",
            "        (2): Sequential(\n",
            "          (0): Embedding(207744, 64)\n",
            "          (1): Linear(in_features=64, out_features=1024, bias=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (layers): ModuleList(\n",
            "      (0): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (1): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (2): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (3): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (4): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (5): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (6): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (7): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (8): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (9): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (10): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (11): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (12): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (13): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (14): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (15): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (adaptive_softmax): AdaptiveSoftmax(\n",
            "      (dropout_module): FairseqDropout()\n",
            "      (lsm): LogSoftmax(dim=1)\n",
            "      (head): TiedHeadModule(\n",
            "        (word_proj): TiedLinear()\n",
            "        (class_proj): Linear(in_features=1024, out_features=2, bias=False)\n",
            "      )\n",
            "      (tail): ModuleList(\n",
            "        (0): Sequential(\n",
            "          (0): TiedLinear()\n",
            "          (1): Dropout(p=0.2, inplace=False)\n",
            "          (2): TiedLinear()\n",
            "        )\n",
            "        (1): Sequential(\n",
            "          (0): TiedLinear()\n",
            "          (1): Dropout(p=0.2, inplace=False)\n",
            "          (2): TiedLinear()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "2021-12-12 06:09:58 | INFO | fairseq_cli.train | task: LanguageModelingTask\n",
            "2021-12-12 06:09:58 | INFO | fairseq_cli.train | model: TransformerLanguageModel\n",
            "2021-12-12 06:09:58 | INFO | fairseq_cli.train | criterion: AdaptiveLoss\n",
            "2021-12-12 06:09:58 | INFO | fairseq_cli.train | num. shared model params: 246,933,504 (num. trained: 246,933,504)\n",
            "2021-12-12 06:09:58 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)\n",
            "2021-12-12 06:09:58 | INFO | fairseq.data.data_utils | loaded 3,760 examples from: data-bin/wikitext-103/valid\n",
            "2021-12-12 06:10:06 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.embeddings.0.0.weight <- decoder.adaptive_softmax.head.word_proj.weight\n",
            "2021-12-12 06:10:06 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.embeddings.0.1.bias <- decoder.embed_tokens.embeddings.1.1.bias\n",
            "2021-12-12 06:10:06 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.embeddings.0.1.bias <- decoder.embed_tokens.embeddings.2.1.bias\n",
            "2021-12-12 06:10:06 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.embeddings.0.1.bias <- decoder.adaptive_softmax.head.class_proj.bias\n",
            "2021-12-12 06:10:06 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.embeddings.1.0.weight <- decoder.adaptive_softmax.tail.0.2.weight\n",
            "2021-12-12 06:10:06 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.embeddings.1.1.weight <- decoder.adaptive_softmax.tail.0.0.weight\n",
            "2021-12-12 06:10:06 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.embeddings.2.0.weight <- decoder.adaptive_softmax.tail.1.2.weight\n",
            "2021-12-12 06:10:06 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.embeddings.2.1.weight <- decoder.adaptive_softmax.tail.1.0.weight\n",
            "2021-12-12 06:10:06 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2021-12-12 06:10:06 | INFO | fairseq.utils | rank   0: capabilities =  6.0  ; total memory = 15.899 GB ; name = Tesla P100-PCIE-16GB                    \n",
            "2021-12-12 06:10:06 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2021-12-12 06:10:06 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
            "2021-12-12 06:10:06 | INFO | fairseq_cli.train | max tokens per device = 3072 and max sentences per device = None\n",
            "2021-12-12 06:10:06 | INFO | fairseq.trainer | Preparing to load checkpoint /content/drive/MyDrive/checkpoints/transformer_wikitext-103/checkpoint_last.pt\n",
            "2021-12-12 06:10:06 | INFO | fairseq.trainer | No existing checkpoint found /content/drive/MyDrive/checkpoints/transformer_wikitext-103/checkpoint_last.pt\n",
            "2021-12-12 06:10:06 | INFO | fairseq.trainer | loading train data for epoch 1\n",
            "2021-12-12 06:10:06 | INFO | fairseq.data.data_utils | loaded 1,801,350 examples from: data-bin/wikitext-103/train\n",
            "2021-12-12 06:10:07 | INFO | fairseq.data.iterators | grouped total_num_itrs = 11201\n",
            "epoch 001:   0% 0/11201 [00:00<?, ?it/s]2021-12-12 06:10:07 | INFO | fairseq.trainer | begin training epoch 1\n",
            "2021-12-12 06:10:07 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 001: 100% 11200/11201 [7:24:39<00:02,  2.38s/it, loss=15845.8, ppl=inf, wps=3864.6, ups=0.42, wpb=9216, bsz=9, num_updates=11200, lr=0.7, gnorm=3.97606e+06, clip=100, train_wall=238, gb_free=3.9, wall=26680]    2021-12-12 13:34:49 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 001 | valid on 'valid' subset:   0% 0/71 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:   1% 1/71 [00:00<00:23,  3.03it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:   3% 2/71 [00:00<00:19,  3.46it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:   4% 3/71 [00:00<00:18,  3.63it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:   6% 4/71 [00:01<00:18,  3.71it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:   7% 5/71 [00:01<00:17,  3.75it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:   8% 6/71 [00:01<00:17,  3.79it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  10% 7/71 [00:01<00:16,  3.80it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  11% 8/71 [00:02<00:16,  3.81it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  13% 9/71 [00:02<00:16,  3.82it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  14% 10/71 [00:02<00:15,  3.83it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  15% 11/71 [00:02<00:15,  3.83it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  17% 12/71 [00:03<00:15,  3.83it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  18% 13/71 [00:03<00:15,  3.83it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  20% 14/71 [00:03<00:14,  3.83it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  21% 15/71 [00:03<00:14,  3.82it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  23% 16/71 [00:04<00:14,  3.83it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  24% 17/71 [00:04<00:14,  3.84it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  25% 18/71 [00:04<00:13,  3.84it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  27% 19/71 [00:05<00:13,  3.84it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  28% 20/71 [00:05<00:13,  3.84it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  30% 21/71 [00:05<00:13,  3.84it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  31% 22/71 [00:05<00:12,  3.84it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  32% 23/71 [00:06<00:12,  3.85it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  34% 24/71 [00:06<00:12,  3.84it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  35% 25/71 [00:06<00:11,  3.84it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  37% 26/71 [00:06<00:11,  3.85it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  38% 27/71 [00:07<00:11,  3.84it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  39% 28/71 [00:07<00:11,  3.84it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  41% 29/71 [00:07<00:10,  3.84it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  42% 30/71 [00:07<00:10,  3.85it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  44% 31/71 [00:08<00:10,  3.84it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  45% 32/71 [00:08<00:10,  3.83it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  46% 33/71 [00:08<00:09,  3.84it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  48% 34/71 [00:08<00:09,  3.84it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  49% 35/71 [00:09<00:09,  3.84it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  51% 36/71 [00:09<00:09,  3.84it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  52% 37/71 [00:09<00:08,  3.82it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  54% 38/71 [00:09<00:08,  3.83it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  55% 39/71 [00:10<00:08,  3.83it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  56% 40/71 [00:10<00:08,  3.83it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  58% 41/71 [00:10<00:07,  3.83it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  59% 42/71 [00:11<00:07,  3.84it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  61% 43/71 [00:11<00:07,  3.84it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  62% 44/71 [00:11<00:07,  3.84it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  63% 45/71 [00:11<00:06,  3.85it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  65% 46/71 [00:12<00:06,  3.85it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  66% 47/71 [00:12<00:06,  3.82it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  68% 48/71 [00:12<00:06,  3.83it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  69% 49/71 [00:12<00:05,  3.83it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  70% 50/71 [00:13<00:05,  3.84it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  72% 51/71 [00:13<00:05,  3.84it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  73% 52/71 [00:13<00:04,  3.84it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  75% 53/71 [00:13<00:04,  3.85it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  76% 54/71 [00:14<00:04,  3.85it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  77% 55/71 [00:14<00:04,  3.85it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  79% 56/71 [00:14<00:03,  3.85it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  80% 57/71 [00:14<00:03,  3.85it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  82% 58/71 [00:15<00:03,  3.84it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  83% 59/71 [00:15<00:03,  3.85it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  85% 60/71 [00:15<00:02,  3.85it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  86% 61/71 [00:15<00:02,  3.85it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  87% 62/71 [00:16<00:02,  3.87it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  89% 63/71 [00:16<00:02,  3.87it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  90% 64/71 [00:16<00:01,  3.88it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  92% 65/71 [00:16<00:01,  3.88it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  93% 66/71 [00:17<00:01,  3.88it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  94% 67/71 [00:17<00:01,  3.88it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  96% 68/71 [00:17<00:00,  3.88it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  97% 69/71 [00:18<00:00,  3.88it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  99% 70/71 [00:18<00:00,  3.89it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset: 100% 71/71 [00:18<00:00,  3.89it/s]\u001b[A\n",
            "                                                                        \u001b[A2021-12-12 13:35:07 | INFO | valid | epoch 001 | valid on 'valid' subset | loss 31016.7 | ppl inf | wps 11817 | wpb 3065.4 | bsz 3 | num_updates 11201\n",
            "2021-12-12 13:35:07 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 1 @ 11201 updates\n",
            "2021-12-12 13:35:07 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/checkpoints/transformer_wikitext-103/checkpoint1.pt\n",
            "2021-12-12 13:35:19 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/checkpoints/transformer_wikitext-103/checkpoint1.pt\n",
            "2021-12-12 13:36:08 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/checkpoints/transformer_wikitext-103/checkpoint1.pt (epoch 1 @ 11201 updates, score 31016.664) (writing took 61.29464115600058 seconds)\n",
            "2021-12-12 13:36:08 | INFO | fairseq_cli.train | end of epoch 1 (average epoch stats below)\n",
            "2021-12-12 13:36:08 | INFO | train | epoch 001 | loss 731442 | ppl inf | wps 3857.4 | ups 0.42 | wpb 9215.9 | bsz 9 | num_updates 11201 | lr 0.700063 | gnorm 1.75954e+07 | clip 100 | train_wall 26643 | gb_free 3.9 | wall 26762\n",
            "2021-12-12 13:36:09 | INFO | fairseq.data.iterators | grouped total_num_itrs = 11201\n",
            "epoch 002:   0% 0/11201 [00:00<?, ?it/s]2021-12-12 13:36:09 | INFO | fairseq.trainer | begin training epoch 2\n",
            "2021-12-12 13:36:09 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "epoch 002: 100% 11200/11201 [7:25:19<00:02,  2.38s/it, loss=87475.4, ppl=inf, wps=3861.9, ups=0.42, wpb=9216, bsz=9, num_updates=22400, lr=0.998614, gnorm=435108, clip=100, train_wall=238, gb_free=3.9, wall=53479]2021-12-12 21:01:30 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "\n",
            "epoch 002 | valid on 'valid' subset:   0% 0/71 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:   1% 1/71 [00:00<00:24,  2.91it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:   3% 2/71 [00:00<00:20,  3.39it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:   4% 3/71 [00:00<00:18,  3.59it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:   6% 4/71 [00:01<00:18,  3.69it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:   7% 5/71 [00:01<00:17,  3.74it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:   8% 6/71 [00:01<00:17,  3.77it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  10% 7/71 [00:01<00:16,  3.79it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  11% 8/71 [00:02<00:16,  3.80it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  13% 9/71 [00:02<00:16,  3.81it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  14% 10/71 [00:02<00:15,  3.82it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  15% 11/71 [00:02<00:15,  3.83it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  17% 12/71 [00:03<00:15,  3.83it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  18% 13/71 [00:03<00:15,  3.84it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  20% 14/71 [00:03<00:14,  3.82it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  21% 15/71 [00:03<00:14,  3.83it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  23% 16/71 [00:04<00:14,  3.83it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  24% 17/71 [00:04<00:14,  3.83it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  25% 18/71 [00:04<00:13,  3.82it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  27% 19/71 [00:05<00:13,  3.82it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  28% 20/71 [00:05<00:13,  3.82it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  30% 21/71 [00:05<00:13,  3.83it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  31% 22/71 [00:05<00:12,  3.83it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  32% 23/71 [00:06<00:12,  3.83it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  34% 24/71 [00:06<00:12,  3.83it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  35% 25/71 [00:06<00:12,  3.83it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  37% 26/71 [00:06<00:11,  3.83it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  38% 27/71 [00:07<00:11,  3.84it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  39% 28/71 [00:07<00:11,  3.84it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  41% 29/71 [00:07<00:10,  3.84it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  42% 30/71 [00:07<00:10,  3.85it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  44% 31/71 [00:08<00:10,  3.85it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  45% 32/71 [00:08<00:10,  3.85it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  46% 33/71 [00:08<00:09,  3.85it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  48% 34/71 [00:08<00:09,  3.85it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  49% 35/71 [00:09<00:09,  3.85it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  51% 36/71 [00:09<00:09,  3.85it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  52% 37/71 [00:09<00:08,  3.84it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  54% 38/71 [00:09<00:08,  3.84it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  55% 39/71 [00:10<00:08,  3.84it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  56% 40/71 [00:10<00:08,  3.84it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  58% 41/71 [00:10<00:07,  3.83it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  59% 42/71 [00:11<00:07,  3.84it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  61% 43/71 [00:11<00:07,  3.84it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  62% 44/71 [00:11<00:07,  3.84it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  63% 45/71 [00:11<00:06,  3.84it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  65% 46/71 [00:12<00:06,  3.84it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  66% 47/71 [00:12<00:06,  3.84it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  68% 48/71 [00:12<00:05,  3.84it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  69% 49/71 [00:12<00:05,  3.83it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  70% 50/71 [00:13<00:05,  3.83it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  72% 51/71 [00:13<00:05,  3.82it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  73% 52/71 [00:13<00:04,  3.82it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  75% 53/71 [00:13<00:04,  3.83it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  76% 54/71 [00:14<00:04,  3.83it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  77% 55/71 [00:14<00:04,  3.83it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  79% 56/71 [00:14<00:03,  3.83it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  80% 57/71 [00:14<00:03,  3.83it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  82% 58/71 [00:15<00:03,  3.83it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  83% 59/71 [00:15<00:03,  3.84it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  85% 60/71 [00:15<00:02,  3.86it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  86% 61/71 [00:15<00:02,  3.85it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  87% 62/71 [00:16<00:02,  3.87it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  89% 63/71 [00:16<00:02,  3.87it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  90% 64/71 [00:16<00:01,  3.88it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  92% 65/71 [00:17<00:01,  3.88it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  93% 66/71 [00:17<00:01,  3.87it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  94% 67/71 [00:17<00:01,  3.87it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  96% 68/71 [00:17<00:00,  3.88it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  97% 69/71 [00:18<00:00,  3.88it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  99% 70/71 [00:18<00:00,  3.88it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset: 100% 71/71 [00:18<00:00,  3.89it/s]\u001b[A\n",
            "                                                                        \u001b[A2021-12-12 21:01:49 | INFO | valid | epoch 002 | valid on 'valid' subset | loss 17749 | ppl inf | wps 11806.8 | wpb 3065.4 | bsz 3 | num_updates 22402 | best_loss 17749\n",
            "2021-12-12 21:01:49 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 2 @ 22402 updates\n",
            "2021-12-12 21:01:49 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/checkpoints/transformer_wikitext-103/checkpoint2.pt\n",
            "2021-12-12 21:02:02 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/checkpoints/transformer_wikitext-103/checkpoint2.pt\n",
            "2021-12-12 21:02:50 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/checkpoints/transformer_wikitext-103/checkpoint2.pt (epoch 2 @ 22402 updates, score 17748.951) (writing took 61.78505180799402 seconds)\n",
            "2021-12-12 21:02:50 | INFO | fairseq_cli.train | end of epoch 2 (average epoch stats below)\n",
            "2021-12-12 21:02:50 | INFO | train | epoch 002 | loss 2.61806e+08 | ppl inf | wps 3851.5 | ups 0.42 | wpb 9215.9 | bsz 9 | num_updates 22402 | lr 0.998614 | gnorm 4.44438e+08 | clip 100 | train_wall 26681 | gb_free 3.9 | wall 53564\n",
            "2021-12-12 21:02:51 | INFO | fairseq.data.iterators | grouped total_num_itrs = 11201\n",
            "epoch 003:   0% 0/11201 [00:00<?, ?it/s]2021-12-12 21:02:51 | INFO | fairseq.trainer | begin training epoch 3\n",
            "2021-12-12 21:02:51 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/fairseq-train\", line 33, in <module>\n",
            "    sys.exit(load_entry_point('fairseq', 'console_scripts', 'fairseq-train')())\n",
            "  File \"/content/fairseq/fairseq_cli/train.py\", line 528, in cli_main\n",
            "    distributed_utils.call_main(cfg, main)\n",
            "  File \"/content/fairseq/fairseq/distributed/utils.py\", line 369, in call_main\n",
            "    main(cfg, **kwargs)\n",
            "  File \"/content/fairseq/fairseq_cli/train.py\", line 188, in main\n",
            "    valid_losses, should_stop = train(cfg, trainer, task, epoch_itr)\n",
            "  File \"/usr/lib/python3.7/contextlib.py\", line 74, in inner\n",
            "    return func(*args, **kwds)\n",
            "  File \"/content/fairseq/fairseq_cli/train.py\", line 303, in train\n",
            "    log_output = trainer.train_step(samples)\n",
            "  File \"/usr/lib/python3.7/contextlib.py\", line 74, in inner\n",
            "    return func(*args, **kwds)\n",
            "  File \"/content/fairseq/fairseq/trainer.py\", line 767, in train_step\n",
            "    **extra_kwargs,\n",
            "  File \"/content/fairseq/fairseq/tasks/fairseq_task.py\", line 516, in train_step\n",
            "    optimizer.backward(loss)\n",
            "  File \"/content/fairseq/fairseq/optim/fairseq_optimizer.py\", line 95, in backward\n",
            "    loss.backward()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\", line 307, in backward\n",
            "    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\", line 156, in backward\n",
            "    allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
            "KeyboardInterrupt\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate the model"
      ],
      "metadata": {
        "id": "iEgLSXrU-0Jv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd fairseq\n",
        "\n",
        "!fairseq-eval-lm data-bin/wikitext-103 --path /content/drive/MyDrive/checkpoints/transformer_wikitext-103/checkpoint_best.pt \\\n",
        "    --sample-break-mode complete \\\n",
        "    --max-tokens 512 \\\n",
        "    --context-window 2560 \\\n",
        "    --softmax-batch 1024 \\\n",
        "    --gen-subset test\n",
        "\n",
        "%cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9YWGEep-2do",
        "outputId": "22c56edd-228b-4455-c3fa-5d1d1039fb94"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/fairseq\n",
            "2021-12-13 15:21:07 | INFO | fairseq_cli.eval_lm | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': '/content/drive/MyDrive/checkpoints/transformer_wikitext-103/checkpoint_best.pt', 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 512, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 512, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 2560, 'softmax_batch': 1024}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': None, 'task': {'_name': 'language_modeling', 'data': 'data-bin/wikitext-103', 'sample_break_mode': 'complete', 'tokens_per_sample': 1024, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 1, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
            "2021-12-13 15:21:08 | INFO | fairseq.tasks.language_modeling | dictionary: 267744 types\n",
            "2021-12-13 15:21:08 | INFO | fairseq_cli.eval_lm | loading model(s) from /content/drive/MyDrive/checkpoints/transformer_wikitext-103/checkpoint_best.pt\n",
            "2021-12-13 15:21:27 | INFO | fairseq_cli.eval_lm | num. model params: 246,933,504\n",
            "2021-12-13 15:21:27 | INFO | fairseq.data.data_utils | loaded 4,358 examples from: data-bin/wikitext-103/test\n",
            "2021-12-13 15:21:28 | INFO | fairseq_cli.eval_lm | data-bin/wikitext-103 test 4,358 examples\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/fairseq-eval-lm\", line 33, in <module>\n",
            "    sys.exit(load_entry_point('fairseq', 'console_scripts', 'fairseq-eval-lm')())\n",
            "  File \"/content/fairseq/fairseq_cli/eval_lm.py\", line 343, in cli_main\n",
            "    distributed_utils.call_main(convert_namespace_to_omegaconf(args), main)\n",
            "  File \"/content/fairseq/fairseq/distributed/utils.py\", line 369, in call_main\n",
            "    main(cfg, **kwargs)\n",
            "  File \"/content/fairseq/fairseq_cli/eval_lm.py\", line 327, in main\n",
            "    remove_bos_token=getattr(cfg.task, \"add_bos_token\", False),\n",
            "  File \"/content/fairseq/fairseq_cli/eval_lm.py\", line 114, in eval_lm\n",
            "    hypos = scorer.generate(models, sample)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/content/fairseq/fairseq/sequence_scorer.py\", line 68, in generate\n",
            "    decoder_out = model(**net_input)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/content/fairseq/fairseq/models/fairseq_model.py\", line 501, in forward\n",
            "    return self.decoder(src_tokens, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/content/fairseq/fairseq/models/transformer/transformer_decoder.py\", line 222, in forward\n",
            "    alignment_heads=alignment_heads,\n",
            "  File \"/content/fairseq/fairseq/models/transformer/transformer_decoder.py\", line 244, in extract_features\n",
            "    alignment_heads,\n",
            "  File \"/content/fairseq/fairseq/models/transformer/transformer_decoder.py\", line 348, in extract_features_scriptable\n",
            "    need_head_weights=bool((idx == alignment_layer)),\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/content/fairseq/fairseq/modules/transformer_layer.py\", line 394, in forward\n",
            "    attn_mask=self_attn_mask,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/content/fairseq/fairseq/modules/multihead_attention.py\", line 191, in forward\n",
            "    v_proj_weight=self.v_proj.weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\", line 5101, in multi_head_attention_forward\n",
            "    attn_output, attn_output_weights = _scaled_dot_product_attention(q, k, v, attn_mask, dropout_p)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\", line 4847, in _scaled_dot_product_attention\n",
            "    attn = softmax(attn, dim=-1)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\", line 1680, in softmax\n",
            "    ret = input.softmax(dim)\n",
            "RuntimeError: CUDA out of memory. Tried to allocate 3.15 GiB (GPU 0; 15.90 GiB total capacity; 8.82 GiB already allocated; 2.73 GiB free; 12.18 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Quantize the model"
      ],
      "metadata": {
        "id": "Q0H0Nym-_X1g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd fairseq\n",
        "\n",
        "!fairseq-train --task language_modeling data-bin/wikitext-103 \\\n",
        "    --save-dir /content/drive/MyDrive/checkpoints/transformer_wikitext-103-quantized \\\n",
        "    --adaptive-input --adaptive-input-cutoff 20000,60000 --adaptive-input-factor 4 \\\n",
        "    --adaptive-softmax-cutoff 20000,60000 --adaptive-softmax-dropout 0.2 --adaptive-softmax-factor 4.0 \\\n",
        "    --arch transformer_lm_gbw \\\n",
        "    --attention-dropout 0.1 --dropout 0.2 --relu-dropout 0.1  \\\n",
        "    --bucket-cap-mb 25 --char-embedder-highway-layers 2 --character-embedding-dim 4 \\\n",
        "    --clip-norm 0.1 --criterion adaptive_loss \\\n",
        "    --ddp-backend legacy_ddp \\\n",
        "    --decoder-attention-heads 8 --decoder-embed-dim 1024 --decoder-ffn-embed-dim 4096 --decoder-input-dim 1024 --decoder-layers 16 --decoder-normalize-before --decoder-output-dim 1024 \\\n",
        "    --keep-last-epochs -1 \\\n",
        "    --min-lr 0.0001 --lr-period-updates 270000 --lr-scheduler cosine --lr-shrink 0.75 --lr 0.05 --stop-min-lr 1e-09 \\\n",
        "    --max-tokens 2944  --tokens-per-sample 2944\\\n",
        "    --momentum 0.99 --no-epoch-checkpoints --no-progress-bar --optimizer nag --required-batch-size-multiple 8 \\\n",
        "    --sample-break-mode none --t-mult 2.0 --skip-invalid-size-inputs-valid-test \\\n",
        "    --tie-adaptive-proj --tie-adaptive-weights --update-freq 3 --weight-decay 0 --seed 1  \\\n",
        "    --log-interval 100 --no-progress-bar --skip-invalid-size-inputs-valid-test \\\n",
        "    --restore-file /content/drive/MyDrive/checkpoints/transformer_wikitext-103/checkpoint_best.pt \\\n",
        "    --max-update 13500 --quantization-config-path examples/quant_noise/transformer_quantization_config.yaml\n",
        "\n",
        "%cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m42-9GG3_IXL",
        "outputId": "2cd519ae-a8a7-49cc-8d32-9442452e8802"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/fairseq\n",
            "2021-12-13 16:03:12 | INFO | fairseq_cli.train | {'_name': None, 'common': {'_name': None, 'no_progress_bar': True, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': 'examples/quant_noise/transformer_quantization_config.yaml', 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'legacy_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 2944, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 2944, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 13500, 'stop_time_hours': 0.0, 'clip_norm': 0.1, 'sentence_avg': False, 'update_freq': [3], 'lr': [0.05], 'stop_min_lr': 1e-09, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': '/content/drive/MyDrive/checkpoints/transformer_wikitext-103-quantized', 'restore_file': '/content/drive/MyDrive/checkpoints/transformer_wikitext-103/checkpoint_best.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'transformer_lm_gbw', 'activation_fn': 'relu', 'dropout': 0.2, 'attention_dropout': 0.1, 'activation_dropout': 0.0, 'relu_dropout': 0.1, 'decoder_embed_dim': 1024, 'decoder_output_dim': 1024, 'decoder_input_dim': 1024, 'decoder_ffn_embed_dim': 4096, 'decoder_layers': 16, 'decoder_attention_heads': 8, 'decoder_normalize_before': True, 'no_decoder_final_norm': True, 'adaptive_softmax_cutoff': '20000,60000', 'adaptive_softmax_dropout': 0.2, 'adaptive_softmax_factor': 4.0, 'no_token_positional_embeddings': False, 'share_decoder_input_output_embed': False, 'character_embeddings': False, 'character_filters': '[(1, 64), (2, 128), (3, 192), (4, 256), (5, 256), (6, 256), (7, 256)]', 'character_embedding_dim': 4, 'char_embedder_highway_layers': 2, 'adaptive_input': True, 'adaptive_input_factor': 4.0, 'adaptive_input_cutoff': '20000,60000', 'tie_adaptive_weights': True, 'tie_adaptive_proj': True, 'decoder_learned_pos': False, 'layernorm_embedding': False, 'no_scale_embedding': False, 'checkpoint_activations': False, 'offload_activations': False, 'decoder_layerdrop': 0.0, 'decoder_layers_to_keep': None, 'quant_noise_pq': 0.0, 'quant_noise_pq_block_size': 8, 'quant_noise_scalar': 0.0, 'min_params_to_wrap': 100000000, 'base_layers': 0, 'base_sublayers': 1, 'base_shuffle': 0, 'scale_fc': False, 'scale_attn': False, 'scale_heads': False, 'scale_resids': False, 'add_bos_token': False, 'tokens_per_sample': 2944, 'max_target_positions': None, 'tpu': False}, 'task': {'_name': 'language_modeling', 'data': 'data-bin/wikitext-103', 'sample_break_mode': 'none', 'tokens_per_sample': 2944, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 1, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'criterion': {'_name': 'adaptive_loss', 'sentence_avg': False, 'ddp_backend': 'legacy_ddp'}, 'optimizer': {'_name': 'nag', 'momentum': 0.99, 'weight_decay': 0.0, 'lr': [0.05]}, 'lr_scheduler': {'_name': 'cosine', 'warmup_updates': 0, 'warmup_init_lr': -1.0, 'lr': [0.05], 'min_lr': 0.0001, 't_mult': 2.0, 'lr_period_updates': 270000.0, 'lr_shrink': 0.75, 'max_update': 13500}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
            "2021-12-13 16:03:13 | INFO | fairseq.tasks.language_modeling | dictionary: 267744 types\n",
            "2021-12-13 16:03:15 | INFO | fairseq_cli.train | TransformerLanguageModel(\n",
            "  (decoder): TransformerDecoder(\n",
            "    (dropout_module): FairseqDropout()\n",
            "    (embed_tokens): AdaptiveInput(\n",
            "      (embeddings): ModuleList(\n",
            "        (0): Sequential(\n",
            "          (0): Embedding(20000, 1024, padding_idx=1)\n",
            "          (1): Linear(in_features=1024, out_features=1024, bias=False)\n",
            "        )\n",
            "        (1): Sequential(\n",
            "          (0): Embedding(40000, 256)\n",
            "          (1): Linear(in_features=256, out_features=1024, bias=False)\n",
            "        )\n",
            "        (2): Sequential(\n",
            "          (0): Embedding(207744, 64)\n",
            "          (1): Linear(in_features=64, out_features=1024, bias=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (embed_positions): SinusoidalPositionalEmbedding()\n",
            "    (layers): ModuleList(\n",
            "      (0): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (1): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (2): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (3): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (4): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (5): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (6): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (7): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (8): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (9): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (10): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (11): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (12): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (13): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (14): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (15): TransformerDecoderLayerBase(\n",
            "        (dropout_module): FairseqDropout()\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (dropout_module): FairseqDropout()\n",
            "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "        )\n",
            "        (activation_dropout_module): FairseqDropout()\n",
            "        (self_attn_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "        (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "        (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "        (final_layer_norm): FusedLayerNorm(torch.Size([1024]), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "    )\n",
            "    (adaptive_softmax): AdaptiveSoftmax(\n",
            "      (dropout_module): FairseqDropout()\n",
            "      (lsm): LogSoftmax(dim=1)\n",
            "      (head): TiedHeadModule(\n",
            "        (word_proj): TiedLinear()\n",
            "        (class_proj): Linear(in_features=1024, out_features=2, bias=False)\n",
            "      )\n",
            "      (tail): ModuleList(\n",
            "        (0): Sequential(\n",
            "          (0): TiedLinear()\n",
            "          (1): Dropout(p=0.2, inplace=False)\n",
            "          (2): TiedLinear()\n",
            "        )\n",
            "        (1): Sequential(\n",
            "          (0): TiedLinear()\n",
            "          (1): Dropout(p=0.2, inplace=False)\n",
            "          (2): TiedLinear()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "2021-12-13 16:03:15 | INFO | fairseq_cli.train | task: LanguageModelingTask\n",
            "2021-12-13 16:03:15 | INFO | fairseq_cli.train | model: TransformerLanguageModel\n",
            "2021-12-13 16:03:15 | INFO | fairseq_cli.train | criterion: AdaptiveLoss\n",
            "2021-12-13 16:03:15 | INFO | fairseq_cli.train | num. shared model params: 246,933,504 (num. trained: 246,933,504)\n",
            "2021-12-13 16:03:15 | INFO | fairseq_cli.train | num. expert model params: 0 (num. trained: 0)\n",
            "2021-12-13 16:03:15 | INFO | fairseq.data.data_utils | loaded 3,760 examples from: data-bin/wikitext-103/valid\n",
            "2021-12-13 16:03:19 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.embeddings.0.0.weight <- decoder.adaptive_softmax.head.word_proj.weight\n",
            "2021-12-13 16:03:19 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.embeddings.0.1.bias <- decoder.embed_tokens.embeddings.1.1.bias\n",
            "2021-12-13 16:03:19 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.embeddings.0.1.bias <- decoder.embed_tokens.embeddings.2.1.bias\n",
            "2021-12-13 16:03:19 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.embeddings.0.1.bias <- decoder.adaptive_softmax.head.class_proj.bias\n",
            "2021-12-13 16:03:19 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.embeddings.1.0.weight <- decoder.adaptive_softmax.tail.0.2.weight\n",
            "2021-12-13 16:03:19 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.embeddings.1.1.weight <- decoder.adaptive_softmax.tail.0.0.weight\n",
            "2021-12-13 16:03:19 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.embeddings.2.0.weight <- decoder.adaptive_softmax.tail.1.2.weight\n",
            "2021-12-13 16:03:19 | INFO | fairseq.trainer | detected shared parameter: decoder.embed_tokens.embeddings.2.1.weight <- decoder.adaptive_softmax.tail.1.0.weight\n",
            "2021-12-13 16:03:19 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2021-12-13 16:03:19 | INFO | fairseq.utils | rank   0: capabilities =  6.0  ; total memory = 15.899 GB ; name = Tesla P100-PCIE-16GB                    \n",
            "2021-12-13 16:03:19 | INFO | fairseq.utils | ***********************CUDA enviroments for all 1 workers***********************\n",
            "2021-12-13 16:03:19 | INFO | fairseq_cli.train | training on 1 devices (GPUs/TPUs)\n",
            "2021-12-13 16:03:19 | INFO | fairseq_cli.train | max tokens per device = 2944 and max sentences per device = None\n",
            "2021-12-13 16:03:19 | INFO | fairseq.trainer | Preparing to load checkpoint /content/drive/MyDrive/checkpoints/transformer_wikitext-103/checkpoint_best.pt\n",
            "2021-12-13 16:03:26 | INFO | fairseq.trainer | Loaded checkpoint /content/drive/MyDrive/checkpoints/transformer_wikitext-103/checkpoint_best.pt (epoch 3 @ 22402 updates)\n",
            "2021-12-13 16:03:27 | INFO | fairseq.trainer | loading train data for epoch 3\n",
            "2021-12-13 16:03:28 | INFO | fairseq.data.data_utils | loaded 1,801,350 examples from: data-bin/wikitext-103/train\n",
            "2021-12-13 16:03:28 | INFO | fairseq.data.iterators | grouped total_num_itrs = 11688\n",
            "2021-12-13 16:03:28 | INFO | fairseq.trainer | begin training epoch 3\n",
            "2021-12-13 16:03:28 | INFO | fairseq.quantization_utils | quantizing model (step=0; layers_to_quantize[step]=decoder\\\\.layers\\\\.\\d+\\\\.fc[12])\n",
            "2021-12-13 16:03:28 | INFO | fairseq.quantization_utils | quantized layers: []\n",
            "2021-12-13 16:03:28 | INFO | fairseq.quantization_utils | Non-compressed model size: 941.98 MB. After quantizing 0 layers, size (indexing + centroids + other): 0.00 MB + 0.00 MB + 941.98 MB = 941.98 MB, compression ratio: 1.00x\n",
            "2021-12-13 16:03:28 | INFO | fairseq_cli.train | Start iterating over samples\n",
            "2021-12-13 16:03:29 | WARNING | fairseq.trainer | OOM: Ran out of memory with exception: CUDA out of memory. Tried to allocate 266.00 MiB (GPU 0; 15.90 GiB total capacity; 14.56 GiB already allocated; 69.75 MiB free; 14.84 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "2021-12-13 16:03:29 | WARNING | fairseq.trainer | |===========================================================================|\n",
            "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
            "|---------------------------------------------------------------------------|\n",
            "|            CUDA OOMs: 1            |        cudaMalloc retries: 1         |\n",
            "|===========================================================================|\n",
            "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocated memory      |   14914 MB |   14914 MB |   17412 MB |    2497 MB |\n",
            "|       from large pool |   14911 MB |   14911 MB |   17406 MB |    2494 MB |\n",
            "|       from small pool |       2 MB |       4 MB |       6 MB |       3 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active memory         |   14914 MB |   14914 MB |   17412 MB |    2497 MB |\n",
            "|       from large pool |   14911 MB |   14911 MB |   17406 MB |    2494 MB |\n",
            "|       from small pool |       2 MB |       4 MB |       6 MB |       3 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved memory   |   15200 MB |   15202 MB |   15202 MB |    2048 KB |\n",
            "|       from large pool |   15196 MB |   15196 MB |   15196 MB |       0 KB |\n",
            "|       from small pool |       4 MB |       6 MB |       6 MB |    2048 KB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable memory |  292521 KB |  298467 KB |    1317 MB |    1031 MB |\n",
            "|       from large pool |  291392 KB |  297280 KB |    1309 MB |    1024 MB |\n",
            "|       from small pool |    1129 KB |    4013 KB |       8 MB |       7 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocations           |     567    |     567    |     981    |     414    |\n",
            "|       from large pool |     332    |     332    |     526    |     194    |\n",
            "|       from small pool |     235    |     331    |     455    |     220    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active allocs         |     567    |     567    |     981    |     414    |\n",
            "|       from large pool |     332    |     332    |     526    |     194    |\n",
            "|       from small pool |     235    |     331    |     455    |     220    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved segments |     253    |     254    |     254    |       1    |\n",
            "|       from large pool |     251    |     251    |     251    |       0    |\n",
            "|       from small pool |       2    |       3    |       3    |       1    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable allocs |     103    |     103    |     205    |     102    |\n",
            "|       from large pool |     100    |     100    |     181    |      81    |\n",
            "|       from small pool |       3    |       4    |      24    |      21    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
            "|===========================================================================|\n",
            "\n",
            "2021-12-13 16:03:29 | WARNING | fairseq.trainer | attempting to recover from OOM in forward/backward pass\n",
            "2021-12-13 16:03:29 | INFO | fairseq_cli.train | Stopping training due to num_updates: 22402 >= max_update: 13500\n",
            "2021-12-13 16:03:29 | INFO | fairseq_cli.train | begin validation on \"valid\" subset\n",
            "2021-12-13 16:03:55 | INFO | valid | epoch 003 | valid on 'valid' subset | loss 17700 | ppl inf | wps 8417.2 | wpb 2941.2 | bsz 1 | num_updates 22402 | best_loss 17700\n",
            "2021-12-13 16:03:55 | INFO | fairseq.checkpoint_utils | Preparing to save checkpoint for epoch 3 @ 22402 updates\n",
            "2021-12-13 16:03:55 | INFO | fairseq.trainer | Saving checkpoint to /content/drive/MyDrive/checkpoints/transformer_wikitext-103-quantized/checkpoint_best.pt\n",
            "2021-12-13 16:04:02 | INFO | fairseq.trainer | Finished saving checkpoint to /content/drive/MyDrive/checkpoints/transformer_wikitext-103-quantized/checkpoint_best.pt\n",
            "2021-12-13 16:04:09 | INFO | fairseq.checkpoint_utils | Saved checkpoint /content/drive/MyDrive/checkpoints/transformer_wikitext-103-quantized/checkpoint_best.pt (epoch 3 @ 22402 updates, score 17699.951) (writing took 14.136138255999867 seconds)\n",
            "2021-12-13 16:04:09 | INFO | fairseq_cli.train | end of epoch 3 (average epoch stats below)\n",
            "2021-12-13 16:04:09 | INFO | train | epoch 003 | lr 0.0491572 | train_wall 41 | wall 50\n",
            "2021-12-13 16:04:09 | INFO | fairseq_cli.train | done training in 40.8 seconds\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate quantized model"
      ],
      "metadata": {
        "id": "cgaRUCQ5CxVv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd fairseq\n",
        "\n",
        "!fairseq-eval-lm data-bin/wikitext-103 --path /content/drive/MyDrive/checkpoints/transformer_wikitext-103-quantized/checkpoint_best.pt \\\n",
        "    --sample-break-mode complete \\\n",
        "    --max-tokens 512 \\\n",
        "    --context-window 2560 \\\n",
        "    --softmax-batch 1024 \\\n",
        "    --gen-subset valid\n",
        "\n",
        "%cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "df1DG2UvC2C-",
        "outputId": "a12fa381-5ab7-49f7-ae48-0fddfb53978b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/fairseq\n",
            "2021-12-13 15:25:54 | INFO | fairseq_cli.eval_lm | {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 100, 'log_format': None, 'log_file': None, 'tensorboard_logdir': None, 'wandb_project': None, 'azureml_logging': False, 'seed': 1, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': False, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': None, 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': '/content/drive/MyDrive/checkpoints/transformer_wikitext-103-quantized/checkpoint_best.pt', 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'pytorch_ddp', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': False, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 1, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': False, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 1, 'skip_invalid_size_inputs_valid_test': False, 'max_tokens': 512, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train', 'valid_subset': 'valid', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 1, 'validate_interval_updates': 0, 'validate_after_updates': 0, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 512, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'valid', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 0, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': False, 'update_freq': [1], 'lr': [0.25], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False}, 'checkpoint': {'_name': None, 'save_dir': 'checkpoints', 'restore_file': 'checkpoint_last.pt', 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': -1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': False, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 2560, 'softmax_batch': 1024}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': None, 'task': {'_name': 'language_modeling', 'data': 'data-bin/wikitext-103', 'sample_break_mode': 'complete', 'tokens_per_sample': 1024, 'output_dictionary_size': -1, 'self_target': False, 'future_target': False, 'past_target': False, 'add_bos_token': False, 'max_target_positions': None, 'shorten_method': 'none', 'shorten_data_split_list': '', 'pad_to_fixed_length': False, 'pad_to_fixed_bsz': False, 'seed': 1, 'batch_size': None, 'batch_size_valid': None, 'dataset_impl': None, 'data_buffer_size': 10, 'tpu': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'criterion': {'_name': 'cross_entropy', 'sentence_avg': True}, 'optimizer': None, 'lr_scheduler': {'_name': 'fixed', 'force_anneal': None, 'lr_shrink': 0.1, 'warmup_updates': 0, 'lr': [0.25]}, 'scoring': {'_name': 'bleu', 'pad': 1, 'eos': 2, 'unk': 3}, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}}\n",
            "2021-12-13 15:25:54 | INFO | fairseq.tasks.language_modeling | dictionary: 267744 types\n",
            "2021-12-13 15:25:54 | INFO | fairseq_cli.eval_lm | loading model(s) from /content/drive/MyDrive/checkpoints/transformer_wikitext-103-quantized/checkpoint_best.pt\n",
            "2021-12-13 15:26:06 | INFO | fairseq_cli.eval_lm | num. model params: 246,933,504\n",
            "2021-12-13 15:26:06 | INFO | fairseq.data.data_utils | loaded 3,760 examples from: data-bin/wikitext-103/valid\n",
            "2021-12-13 15:26:06 | INFO | fairseq_cli.eval_lm | data-bin/wikitext-103 valid 3,760 examples\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/fairseq-eval-lm\", line 33, in <module>\n",
            "    sys.exit(load_entry_point('fairseq', 'console_scripts', 'fairseq-eval-lm')())\n",
            "  File \"/content/fairseq/fairseq_cli/eval_lm.py\", line 343, in cli_main\n",
            "    distributed_utils.call_main(convert_namespace_to_omegaconf(args), main)\n",
            "  File \"/content/fairseq/fairseq/distributed/utils.py\", line 369, in call_main\n",
            "    main(cfg, **kwargs)\n",
            "  File \"/content/fairseq/fairseq_cli/eval_lm.py\", line 327, in main\n",
            "    remove_bos_token=getattr(cfg.task, \"add_bos_token\", False),\n",
            "  File \"/content/fairseq/fairseq_cli/eval_lm.py\", line 114, in eval_lm\n",
            "    hypos = scorer.generate(models, sample)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/content/fairseq/fairseq/sequence_scorer.py\", line 68, in generate\n",
            "    decoder_out = model(**net_input)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/content/fairseq/fairseq/models/fairseq_model.py\", line 501, in forward\n",
            "    return self.decoder(src_tokens, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/content/fairseq/fairseq/models/transformer/transformer_decoder.py\", line 222, in forward\n",
            "    alignment_heads=alignment_heads,\n",
            "  File \"/content/fairseq/fairseq/models/transformer/transformer_decoder.py\", line 244, in extract_features\n",
            "    alignment_heads,\n",
            "  File \"/content/fairseq/fairseq/models/transformer/transformer_decoder.py\", line 348, in extract_features_scriptable\n",
            "    need_head_weights=bool((idx == alignment_layer)),\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/content/fairseq/fairseq/modules/transformer_layer.py\", line 394, in forward\n",
            "    attn_mask=self_attn_mask,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1102, in _call_impl\n",
            "    return forward_call(*input, **kwargs)\n",
            "  File \"/content/fairseq/fairseq/modules/multihead_attention.py\", line 191, in forward\n",
            "    v_proj_weight=self.v_proj.weight,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\", line 5101, in multi_head_attention_forward\n",
            "    attn_output, attn_output_weights = _scaled_dot_product_attention(q, k, v, attn_mask, dropout_p)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\", line 4847, in _scaled_dot_product_attention\n",
            "    attn = softmax(attn, dim=-1)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\", line 1680, in softmax\n",
            "    ret = input.softmax(dim)\n",
            "RuntimeError: CUDA out of memory. Tried to allocate 5.71 GiB (GPU 0; 15.90 GiB total capacity; 14.37 GiB already allocated; 305.75 MiB free; 14.61 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "/content\n"
          ]
        }
      ]
    }
  ]
}